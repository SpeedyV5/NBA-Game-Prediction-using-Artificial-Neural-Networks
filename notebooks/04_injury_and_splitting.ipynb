{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Injury Features & Dataset Splitting\n",
        "\n",
        "Bu notebook, Ekin'in sorumluluÄŸundaki gÃ¶revleri gerÃ§ekleÅŸtirir:\n",
        "\n",
        "1. **Injury Data Processing**: Raw injury verilerini temizle ve birleÅŸtir\n",
        "2. **Injury Feature Generation**: MaÃ§ bazlÄ± injury feature'larÄ±nÄ± Ã¼ret\n",
        "3. **Final Dataset**: Core features + injury features ile final dataset oluÅŸtur\n",
        "4. **Train/Val/Test Split**: Zaman bazlÄ± split yap\n",
        "\n",
        "## Input Dosyalar\n",
        "- `data_interim/games_with_core_features.csv` (Ä°brahim'den)\n",
        "- `data_raw/injury_reports_raw/` (Raw injury PDF'lerden parse edilmiÅŸ CSV'ler)\n",
        "- `data_raw/nbastuffer_2025_2026_player_stats_raw.csv` (Oyuncu dakika bilgileri)\n",
        "\n",
        "## Output Dosyalar\n",
        "- `data_interim/injury_reports_clean.csv` (TemizlenmiÅŸ injury verileri)\n",
        "- `data_processed/games_with_all_features.csv` (Core + injury features)\n",
        "- `data_processed/train_set.csv`\n",
        "- `data_processed/val_set.csv`\n",
        "- `data_processed/test_set.csv`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proje root: c:\\Users\\user\\Desktop\\ann odev\n",
            "Ã‡alÄ±ÅŸma dizini: c:\\Users\\user\\Desktop\\ann odev\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Proje root dizinini bul\n",
        "project_root = Path().absolute().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Ã‡alÄ±ÅŸma dizinini proje root'una ayarla\n",
        "os.chdir(project_root)\n",
        "\n",
        "print(f\"Proje root: {project_root}\")\n",
        "print(f\"Ã‡alÄ±ÅŸma dizini: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModÃ¼ller yÃ¼klendi!\n"
          ]
        }
      ],
      "source": [
        "# ModÃ¼lleri import et\n",
        "from src.features.injury_features import (\n",
        "    load_and_clean_injury_reports,\n",
        "    load_player_minutes,\n",
        "    add_injury_features,\n",
        "    build_injury_features\n",
        ")\n",
        "\n",
        "from src.data.split_dataset import (\n",
        "    analyze_date_range,\n",
        "    split_dataset_by_time,\n",
        "    split_dataset_random,\n",
        "    save_splits,\n",
        "    print_split_stats,\n",
        "    print_split_stats_random,\n",
        "    validate_splits,\n",
        "    create_time_based_split,\n",
        "    create_random_split,\n",
        "    suggest_split_dates\n",
        ")\n",
        "\n",
        "print(\"ModÃ¼ller yÃ¼klendi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Core Features DosyasÄ±nÄ± Kontrol Et\n",
        "\n",
        "Ä°brahim'in build_features.py pipeline'Ä±nÄ±n Ã§Ä±ktÄ±sÄ±nÄ± kontrol edelim. EÄŸer yoksa, oluÅŸturalÄ±m.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "master_merged.csv mevcut: data_processed\\master_merged.csv\n",
            "\n",
            "Core features oluÅŸturuluyor...\n",
            "[OK] games_with_core_features.csv written -> data_interim\\games_with_core_features.csv (17832 rows, 219 cols)\n",
            "[OK] model_dataset.csv written -> data_processed\\model_dataset.csv (17820 rows, 94 cols)\n"
          ]
        }
      ],
      "source": [
        "# Ä°lk olarak Ä°brahim'in pipeline'Ä±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±p core features'Ä± Ã¼retelim\n",
        "from src.features.build_features import build_model_dataset\n",
        "\n",
        "# master_merged.csv yoksa, Ã¶nce onu oluÅŸturmamÄ±z gerekiyor\n",
        "master_csv = Path(\"data_processed/master_merged.csv\")\n",
        "\n",
        "if not master_csv.exists():\n",
        "    print(\"master_merged.csv bulunamadÄ±!\")\n",
        "    print(\"Ã–nce 02_clean_merge.ipynb notebook'unu Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
        "else:\n",
        "    print(f\"master_merged.csv mevcut: {master_csv}\")\n",
        "    \n",
        "    # Core features'Ä± oluÅŸtur\n",
        "    core_features_path = Path(\"data_interim/games_with_core_features.csv\")\n",
        "    if not core_features_path.exists():\n",
        "        print(\"\\nCore features oluÅŸturuluyor...\")\n",
        "        build_model_dataset(\n",
        "            master_csv=master_csv,\n",
        "            output_csv=\"data_processed/model_dataset.csv\",\n",
        "            write_interim=True\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Core features mevcut: {core_features_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core Features:\n",
            "  SatÄ±r sayÄ±sÄ±: 17,832\n",
            "  Kolon sayÄ±sÄ±: 219\n",
            "\n",
            "Kolonlar:\n",
            "  1. gameId\n",
            "  2. game_date\n",
            "  3. season_year\n",
            "  4. home_team\n",
            "  5. away_team\n",
            "  6. home_team_code\n",
            "  7. away_team_code\n",
            "  8. season_type\n",
            "  9. matchup\n",
            "  10. RANK\n",
            "  11. home_team_CONF\n",
            "  12. home_team_DIVISION\n",
            "  13. home_team_GP\n",
            "  14. home_team_PPG\n",
            "  15. home_team_oPPG\n",
            "  16. home_team_pDIFF\n",
            "  17. home_team_PACE\n",
            "  18. home_team_oEFF\n",
            "  19. home_team_dEFF\n",
            "  20. home_team_eDIFF\n",
            "  21. home_team_SoS\n",
            "  22. home_team_rSoS\n",
            "  23. home_team_SAR\n",
            "  24. home_team_CONS\n",
            "  25. home_team_A4F\n",
            "  26. home_team_W\n",
            "  27. home_team_L\n",
            "  28. home_team_WIN%\n",
            "  29. home_team_eWIN%\n",
            "  30. home_team_pWIN%\n",
            "  31. home_team_ACH\n",
            "  32. home_team_STRK\n",
            "  33. RANK_away_stats\n",
            "  34. away_team_CONF\n",
            "  35. away_team_DIVISION\n",
            "  36. away_team_GP\n",
            "  37. away_team_PPG\n",
            "  38. away_team_oPPG\n",
            "  39. away_team_pDIFF\n",
            "  40. away_team_PACE\n",
            "  41. away_team_oEFF\n",
            "  42. away_team_dEFF\n",
            "  43. away_team_eDIFF\n",
            "  44. away_team_SoS\n",
            "  45. away_team_rSoS\n",
            "  46. away_team_SAR\n",
            "  47. away_team_CONS\n",
            "  48. away_team_A4F\n",
            "  49. away_team_W\n",
            "  50. away_team_L\n",
            "  51. away_team_WIN%\n",
            "  52. away_team_eWIN%\n",
            "  53. away_team_pWIN%\n",
            "  54. away_team_ACH\n",
            "  55. away_team_STRK\n",
            "  56. RANK_home_rest\n",
            "  57. OPPONENT TODAY\n",
            "  58. home_rest_4IN5-B2B GP\n",
            "  59. home_rest_4IN5-B2B W%\n",
            "  60. home_rest_4IN5-B2B AED\n",
            "  61. home_rest_3IN4-B2B GP\n",
            "  62. home_rest_3IN4-B2B W%\n",
            "  63. home_rest_3IN4-B2B AED\n",
            "  64. home_rest_B2B GP\n",
            "  65. home_rest_B2B W%\n",
            "  66. home_rest_B2B AED\n",
            "  67. home_rest_3IN4 GP\n",
            "  68. home_rest_3IN4 W%\n",
            "  69. home_rest_3IN4 AED\n",
            "  70. home_rest_1 DAY GP\n",
            "  71. home_rest_1 DAY W%\n",
            "  72. home_rest_1 DAY AED\n",
            "  73. home_rest_2 DAYS GP\n",
            "  74. home_rest_2 DAYS W%\n",
            "  75. home_rest_2 DAYS AED\n",
            "  76. home_rest_3+ DAYS GP\n",
            "  77. home_rest_3+ DAYS W%\n",
            "  78. home_rest_3+ DAYS AED\n",
            "  79. RANK_away_rest\n",
            "  80. OPPONENT TODAY_away_rest\n",
            "  81. away_rest_4IN5-B2B GP\n",
            "  82. away_rest_4IN5-B2B W%\n",
            "  83. away_rest_4IN5-B2B AED\n",
            "  84. away_rest_3IN4-B2B GP\n",
            "  85. away_rest_3IN4-B2B W%\n",
            "  86. away_rest_3IN4-B2B AED\n",
            "  87. away_rest_B2B GP\n",
            "  88. away_rest_B2B W%\n",
            "  89. away_rest_B2B AED\n",
            "  90. away_rest_3IN4 GP\n",
            "  91. away_rest_3IN4 W%\n",
            "  92. away_rest_3IN4 AED\n",
            "  93. away_rest_1 DAY GP\n",
            "  94. away_rest_1 DAY W%\n",
            "  95. away_rest_1 DAY AED\n",
            "  96. away_rest_2 DAYS GP\n",
            "  97. away_rest_2 DAYS W%\n",
            "  98. away_rest_2 DAYS AED\n",
            "  99. away_rest_3+ DAYS GP\n",
            "  100. away_rest_3+ DAYS W%\n",
            "  101. away_rest_3+ DAYS AED\n",
            "  102. RANK_home_schedule\n",
            "  103. home_schedule_TOTAL GAMES\n",
            "  104. home_schedule_5-IN-7\n",
            "  105. home_schedule_3IN4-B2B\n",
            "  106. home_schedule_SOFT-B2B\n",
            "  107. home_schedule_ALL B2B\n",
            "  108. home_schedule_TOTAL B2B ON THE ROAD\n",
            "  109. home_schedule_TOTAL B2B AT HOME\n",
            "  110. home_schedule_3IN4\n",
            "  111. home_schedule_1-DAY REST\n",
            "  112. home_schedule_2-DAYS REST\n",
            "  113. home_schedule_3+DAYS REST\n",
            "  114. home_schedule_REST ADVANTAGE\n",
            "  115. home_schedule_REST DISADVANTAGE\n",
            "  116. home_schedule_BOTH TEAMS  RESTED or NO-REST\n",
            "  117. RANK_away_schedule\n",
            "  118. away_schedule_TOTAL GAMES\n",
            "  119. away_schedule_5-IN-7\n",
            "  120. away_schedule_3IN4-B2B\n",
            "  121. away_schedule_SOFT-B2B\n",
            "  122. away_schedule_ALL B2B\n",
            "  123. away_schedule_TOTAL B2B ON THE ROAD\n",
            "  124. away_schedule_TOTAL B2B AT HOME\n",
            "  125. away_schedule_3IN4\n",
            "  126. away_schedule_1-DAY REST\n",
            "  127. away_schedule_2-DAYS REST\n",
            "  128. away_schedule_3+DAYS REST\n",
            "  129. away_schedule_REST ADVANTAGE\n",
            "  130. away_schedule_REST DISADVANTAGE\n",
            "  131. away_schedule_BOTH TEAMS  RESTED or NO-REST\n",
            "  132. month\n",
            "  133. day_of_week\n",
            "  134. is_weekend\n",
            "  135. is_playoff\n",
            "  136. home_team_win\n",
            "  137. score_diff\n",
            "  138. home_elo_before\n",
            "  139. away_elo_before\n",
            "  140. diff_elo\n",
            "  141. home_roll_w5_win_rate\n",
            "  142. home_roll_w5_avg_score_diff\n",
            "  143. home_roll_w5_avg_points_for\n",
            "  144. home_roll_w5_avg_points_against\n",
            "  145. home_roll_w10_win_rate\n",
            "  146. home_roll_w10_avg_score_diff\n",
            "  147. home_roll_w10_avg_points_for\n",
            "  148. home_roll_w10_avg_points_against\n",
            "  149. away_roll_w5_win_rate\n",
            "  150. away_roll_w5_avg_score_diff\n",
            "  151. away_roll_w5_avg_points_for\n",
            "  152. away_roll_w5_avg_points_against\n",
            "  153. away_roll_w10_win_rate\n",
            "  154. away_roll_w10_avg_score_diff\n",
            "  155. away_roll_w10_avg_points_for\n",
            "  156. away_roll_w10_avg_points_against\n",
            "  157. diff_roll_w5_win_rate\n",
            "  158. diff_roll_w5_avg_score_diff\n",
            "  159. diff_roll_w5_avg_points_for\n",
            "  160. diff_roll_w5_avg_points_against\n",
            "  161. diff_roll_w10_win_rate\n",
            "  162. diff_roll_w10_avg_score_diff\n",
            "  163. diff_roll_w10_avg_points_for\n",
            "  164. diff_roll_w10_avg_points_against\n",
            "  165. diff_team_GP\n",
            "  166. diff_team_PPG\n",
            "  167. diff_team_oPPG\n",
            "  168. diff_team_pDIFF\n",
            "  169. diff_team_PACE\n",
            "  170. diff_team_oEFF\n",
            "  171. diff_team_dEFF\n",
            "  172. diff_team_eDIFF\n",
            "  173. diff_team_SoS\n",
            "  174. diff_team_rSoS\n",
            "  175. diff_team_SAR\n",
            "  176. diff_team_CONS\n",
            "  177. diff_team_A4F\n",
            "  178. diff_team_W\n",
            "  179. diff_team_L\n",
            "  180. diff_team_WIN%\n",
            "  181. diff_team_eWIN%\n",
            "  182. diff_team_pWIN%\n",
            "  183. diff_team_ACH\n",
            "  184. diff_team_STRK\n",
            "  185. diff_rest_4IN5-B2B GP\n",
            "  186. diff_rest_4IN5-B2B W%\n",
            "  187. diff_rest_4IN5-B2B AED\n",
            "  188. diff_rest_3IN4-B2B GP\n",
            "  189. diff_rest_3IN4-B2B W%\n",
            "  190. diff_rest_3IN4-B2B AED\n",
            "  191. diff_rest_B2B GP\n",
            "  192. diff_rest_B2B W%\n",
            "  193. diff_rest_B2B AED\n",
            "  194. diff_rest_3IN4 GP\n",
            "  195. diff_rest_3IN4 W%\n",
            "  196. diff_rest_3IN4 AED\n",
            "  197. diff_rest_1 DAY GP\n",
            "  198. diff_rest_1 DAY W%\n",
            "  199. diff_rest_1 DAY AED\n",
            "  200. diff_rest_2 DAYS GP\n",
            "  201. diff_rest_2 DAYS W%\n",
            "  202. diff_rest_2 DAYS AED\n",
            "  203. diff_rest_3+ DAYS GP\n",
            "  204. diff_rest_3+ DAYS W%\n",
            "  205. diff_rest_3+ DAYS AED\n",
            "  206. diff_schedule_TOTAL GAMES\n",
            "  207. diff_schedule_5-IN-7\n",
            "  208. diff_schedule_3IN4-B2B\n",
            "  209. diff_schedule_SOFT-B2B\n",
            "  210. diff_schedule_ALL B2B\n",
            "  211. diff_schedule_TOTAL B2B ON THE ROAD\n",
            "  212. diff_schedule_TOTAL B2B AT HOME\n",
            "  213. diff_schedule_3IN4\n",
            "  214. diff_schedule_1-DAY REST\n",
            "  215. diff_schedule_2-DAYS REST\n",
            "  216. diff_schedule_3+DAYS REST\n",
            "  217. diff_schedule_REST ADVANTAGE\n",
            "  218. diff_schedule_REST DISADVANTAGE\n",
            "  219. diff_schedule_BOTH TEAMS  RESTED or NO-REST\n",
            "\n",
            "Ä°lk 3 satÄ±r:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gameId</th>\n",
              "      <th>game_date</th>\n",
              "      <th>season_year</th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>home_team_code</th>\n",
              "      <th>away_team_code</th>\n",
              "      <th>season_type</th>\n",
              "      <th>matchup</th>\n",
              "      <th>RANK</th>\n",
              "      <th>...</th>\n",
              "      <th>diff_schedule_ALL B2B</th>\n",
              "      <th>diff_schedule_TOTAL B2B ON THE ROAD</th>\n",
              "      <th>diff_schedule_TOTAL B2B AT HOME</th>\n",
              "      <th>diff_schedule_3IN4</th>\n",
              "      <th>diff_schedule_1-DAY REST</th>\n",
              "      <th>diff_schedule_2-DAYS REST</th>\n",
              "      <th>diff_schedule_3+DAYS REST</th>\n",
              "      <th>diff_schedule_REST ADVANTAGE</th>\n",
              "      <th>diff_schedule_REST DISADVANTAGE</th>\n",
              "      <th>diff_schedule_BOTH TEAMS  RESTED or NO-REST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21000001</td>\n",
              "      <td>2010-10-26</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>Miami Heat</td>\n",
              "      <td>BOS</td>\n",
              "      <td>MIA</td>\n",
              "      <td>regular</td>\n",
              "      <td>BOS vs. MIA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>-5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21000002</td>\n",
              "      <td>2010-10-26</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>Portland Trail Blazers</td>\n",
              "      <td>Phoenix Suns</td>\n",
              "      <td>POR</td>\n",
              "      <td>PHX</td>\n",
              "      <td>regular</td>\n",
              "      <td>PHX @ POR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21000003</td>\n",
              "      <td>2010-10-26</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>Los Angeles Lakers</td>\n",
              "      <td>Houston Rockets</td>\n",
              "      <td>LAL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>regular</td>\n",
              "      <td>HOU @ LAL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 219 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     gameId   game_date season_year               home_team        away_team  \\\n",
              "0  21000001  2010-10-26     2010-11          Boston Celtics       Miami Heat   \n",
              "1  21000002  2010-10-26     2010-11  Portland Trail Blazers     Phoenix Suns   \n",
              "2  21000003  2010-10-26     2010-11      Los Angeles Lakers  Houston Rockets   \n",
              "\n",
              "  home_team_code away_team_code season_type      matchup  RANK  ...  \\\n",
              "0            BOS            MIA     regular  BOS vs. MIA   NaN  ...   \n",
              "1            POR            PHX     regular    PHX @ POR   NaN  ...   \n",
              "2            LAL            HOU     regular    HOU @ LAL   NaN  ...   \n",
              "\n",
              "  diff_schedule_ALL B2B diff_schedule_TOTAL B2B ON THE ROAD  \\\n",
              "0                    -2                                   1   \n",
              "1                    -1                                   2   \n",
              "2                     0                                  -2   \n",
              "\n",
              "   diff_schedule_TOTAL B2B AT HOME  diff_schedule_3IN4  \\\n",
              "0                               -3                   0   \n",
              "1                               -3                  -3   \n",
              "2                                2                   1   \n",
              "\n",
              "   diff_schedule_1-DAY REST  diff_schedule_2-DAYS REST  \\\n",
              "0                         5                         -5   \n",
              "1                         5                         -1   \n",
              "2                        -1                          0   \n",
              "\n",
              "   diff_schedule_3+DAYS REST  diff_schedule_REST ADVANTAGE  \\\n",
              "0                          2                             1   \n",
              "1                          0                             3   \n",
              "2                          0                             1   \n",
              "\n",
              "   diff_schedule_REST DISADVANTAGE  \\\n",
              "0                               -2   \n",
              "1                               -3   \n",
              "2                                1   \n",
              "\n",
              "   diff_schedule_BOTH TEAMS  RESTED or NO-REST  \n",
              "0                                            1  \n",
              "1                                            0  \n",
              "2                                           -2  \n",
              "\n",
              "[3 rows x 219 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tarih aralÄ±ÄŸÄ±:\n",
            "  Min: 2010-10-26 00:00:00\n",
            "  Max: 2025-11-15 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Core features dosyasÄ±nÄ± yÃ¼kle ve incele\n",
        "core_features_path = Path(\"data_interim/games_with_core_features.csv\")\n",
        "\n",
        "if core_features_path.exists():\n",
        "    core_df = pd.read_csv(core_features_path, low_memory=False)\n",
        "    \n",
        "    print(f\"Core Features:\")\n",
        "    print(f\"  SatÄ±r sayÄ±sÄ±: {len(core_df):,}\")\n",
        "    print(f\"  Kolon sayÄ±sÄ±: {len(core_df.columns)}\")\n",
        "    \n",
        "    print(f\"\\nKolonlar:\")\n",
        "    for i, col in enumerate(core_df.columns):\n",
        "        print(f\"  {i+1}. {col}\")\n",
        "    \n",
        "    print(f\"\\nÄ°lk 3 satÄ±r:\")\n",
        "    display(core_df.head(3))\n",
        "    \n",
        "    # Tarih aralÄ±ÄŸÄ±nÄ± kontrol et\n",
        "    if 'game_date' in core_df.columns:\n",
        "        core_df['game_date'] = pd.to_datetime(core_df['game_date'])\n",
        "        print(f\"\\nTarih aralÄ±ÄŸÄ±:\")\n",
        "        print(f\"  Min: {core_df['game_date'].min()}\")\n",
        "        print(f\"  Max: {core_df['game_date'].max()}\")\n",
        "else:\n",
        "    print(\"Core features dosyasÄ± bulunamadÄ±!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Injury Data Processing\n",
        "\n",
        "Raw injury verilerini yÃ¼kle, temizle ve birleÅŸtir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Injury raw klasÃ¶rÃ¼ bulunamadÄ±!\n"
          ]
        }
      ],
      "source": [
        "# Raw injury klasÃ¶rÃ¼nÃ¼ kontrol et\n",
        "injury_raw_dir = Path(\"data_raw/injury_reports_raw\")\n",
        "\n",
        "if injury_raw_dir.exists():\n",
        "    files = list(injury_raw_dir.glob(\"*\"))\n",
        "    print(f\"Injury raw dosyalarÄ± ({len(files)} dosya):\")\n",
        "    for f in files:\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    print(\"Injury raw klasÃ¶rÃ¼ bulunamadÄ±!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ Injury klasÃ¶rÃ¼ bulunamadÄ±: data_raw\\injury_reports_raw\n",
            "âš ï¸ Injury verisi bulunamadÄ± veya parse edilemedi.\n",
            "   â†’ Ä°brahim'in yaklaÅŸÄ±mÄ±: Injury olmadan devam edilecek (inference-time'da kullanÄ±lacak)\n"
          ]
        }
      ],
      "source": [
        "# Injury verilerini yÃ¼kle ve temizle\n",
        "# NOT: Injury verisi sÄ±nÄ±rlÄ± (sadece 1 gÃ¼nlÃ¼k), bu yÃ¼zden opsiyonel\n",
        "try:\n",
        "    injury_df = load_and_clean_injury_reports(\n",
        "        raw_dir=\"data_raw/injury_reports_raw/\",\n",
        "        output_path=\"data_interim/injury_reports_clean.csv\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Injury verisi yÃ¼klenirken hata: {e}\")\n",
        "    injury_df = pd.DataFrame()\n",
        "\n",
        "if len(injury_df) > 0:\n",
        "    print(f\"\\nâœ… TemizlenmiÅŸ injury verileri:\")\n",
        "    print(f\"  SatÄ±r sayÄ±sÄ±: {len(injury_df)}\")\n",
        "    print(f\"\\nKolonlar: {list(injury_df.columns)}\")\n",
        "    print(f\"\\nÄ°lk 10 satÄ±r:\")\n",
        "    display(injury_df.head(10))\n",
        "\n",
        "    print(f\"\\nStatus daÄŸÄ±lÄ±mÄ±:\")\n",
        "    print(injury_df['status'].value_counts())\n",
        "else:\n",
        "    print(\"âš ï¸ Injury verisi bulunamadÄ± veya parse edilemedi.\")\n",
        "    print(\"   â†’ Ä°brahim'in yaklaÅŸÄ±mÄ±: Injury olmadan devam edilecek (inference-time'da kullanÄ±lacak)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Player Minutes Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ Player stats dosyasÄ± bulunamadÄ±: data_raw\\nbastuffer_2025_2026_player_stats_raw.csv\n",
            "âš ï¸ Player minutes verisi bulunamadÄ± - Injury features iÃ§in gerekli deÄŸil\n"
          ]
        }
      ],
      "source": [
        "# Player minutes verilerini yÃ¼kle (opsiyonel - injury iÃ§in gerekli)\n",
        "try:\n",
        "    player_minutes_df = load_player_minutes(\n",
        "        player_stats_path=\"data_raw/nbastuffer_2025_2026_player_stats_raw.csv\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Player minutes yÃ¼klenirken hata: {e}\")\n",
        "    player_minutes_df = pd.DataFrame()\n",
        "\n",
        "if len(player_minutes_df) > 0:\n",
        "    print(f\"\\nâœ… Player minutes verileri:\")\n",
        "    print(f\"  Oyuncu sayÄ±sÄ±: {len(player_minutes_df)}\")\n",
        "\n",
        "    print(f\"\\nEn Ã§ok oynayan oyuncular:\")\n",
        "    top_players = player_minutes_df.nlargest(15, 'avg_minutes_per_game')\n",
        "    display(top_players)\n",
        "\n",
        "    print(f\"\\nDakika daÄŸÄ±lÄ±mÄ±:\")\n",
        "    print(player_minutes_df['avg_minutes_per_game'].describe())\n",
        "\n",
        "    # Key players (25+ dk)\n",
        "    key_players = player_minutes_df[player_minutes_df['avg_minutes_per_game'] >= 25]\n",
        "    print(f\"\\nKey players (25+ dk): {len(key_players)} oyuncu\")\n",
        "else:\n",
        "    print(\"âš ï¸ Player minutes verisi bulunamadÄ± - Injury features iÃ§in gerekli deÄŸil\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Injury Features Generation\n",
        "\n",
        "Core features'a injury feature'larÄ±nÄ± ekle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ Yeterli injury verisi yok - Ä°brahim'in yaklaÅŸÄ±mÄ± uygulanÄ±yor:\n",
            "   â†’ Injury feature'larÄ± 0 olarak ayarlanacak\n",
            "   â†’ Model sadece core features ile eÄŸitilecek\n",
            "   â†’ Injury, inference-time'da ayrÄ± kullanÄ±lacak\n",
            "\n",
            "ðŸ“Š Final dataset:\n",
            "  SatÄ±r sayÄ±sÄ±: 17,832\n",
            "  Kolon sayÄ±sÄ±: 225\n"
          ]
        }
      ],
      "source": [
        "# Injury features ekle (veya placeholder kullan)\n",
        "if core_features_path.exists():\n",
        "    # Injury verisi varsa ve yeterliyse kullan\n",
        "    if len(injury_df) > 0 and 'player_minutes_df' in dir() and len(player_minutes_df) > 0:\n",
        "        try:\n",
        "            games_with_injury = add_injury_features(\n",
        "                games_df=core_df,\n",
        "                injury_df=injury_df,\n",
        "                player_minutes_df=player_minutes_df,\n",
        "                key_player_minutes_threshold=25.0\n",
        "            )\n",
        "            print(f\"\\nâœ… Injury features eklendi:\")\n",
        "            new_cols = [col for col in games_with_injury.columns if col not in core_df.columns]\n",
        "            print(f\"  Yeni kolonlar: {new_cols}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Injury features eklenirken hata: {e}\")\n",
        "            games_with_injury = core_df.copy()\n",
        "    else:\n",
        "        # Ä°brahim'in yaklaÅŸÄ±mÄ±: Injury verisi yetersiz, placeholder kullan\n",
        "        print(\"âš ï¸ Yeterli injury verisi yok - Ä°brahim'in yaklaÅŸÄ±mÄ± uygulanÄ±yor:\")\n",
        "        print(\"   â†’ Injury feature'larÄ± 0 olarak ayarlanacak\")\n",
        "        print(\"   â†’ Model sadece core features ile eÄŸitilecek\")\n",
        "        print(\"   â†’ Injury, inference-time'da ayrÄ± kullanÄ±lacak\")\n",
        "        \n",
        "        games_with_injury = core_df.copy()\n",
        "        # Placeholder injury kolonlarÄ± (hepsi 0)\n",
        "        games_with_injury['injury_count_home'] = 0\n",
        "        games_with_injury['injury_count_away'] = 0\n",
        "        games_with_injury['expected_minutes_lost_home'] = 0.0\n",
        "        games_with_injury['expected_minutes_lost_away'] = 0.0\n",
        "        games_with_injury['any_key_player_out_home'] = 0\n",
        "        games_with_injury['any_key_player_out_away'] = 0\n",
        "\n",
        "    print(f\"\\nðŸ“Š Final dataset:\")\n",
        "    print(f\"  SatÄ±r sayÄ±sÄ±: {len(games_with_injury):,}\")\n",
        "    print(f\"  Kolon sayÄ±sÄ±: {len(games_with_injury.columns)}\")\n",
        "else:\n",
        "    print(\"âŒ Core features dosyasÄ± bulunamadÄ±!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset kaydedildi: data_processed\\games_with_all_features.csv\n",
            "   17,832 satÄ±r, 225 kolon\n"
          ]
        }
      ],
      "source": [
        "# Final dataset'i kaydet\n",
        "output_path = Path(\"data_processed/games_with_all_features.csv\")\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "games_with_injury.to_csv(output_path, index=False)\n",
        "print(f\"Final dataset kaydedildi: {output_path}\")\n",
        "print(f\"   {len(games_with_injury):,} satÄ±r, {len(games_with_injury.columns)} kolon\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Dataset Splitting (Random Shuffle)\n",
        "\n",
        "Rastgele karÄ±ÅŸtÄ±rmalÄ± (random shuffle) train/val/test split yap.\n",
        "\n",
        "**Neden Random Split?**\n",
        "- Basketbolun oyun yapÄ±sÄ± yÄ±llar iÃ§inde deÄŸiÅŸtiÄŸi iÃ§in, sadece eski verilerle eÄŸitilip gÃ¼ncel maÃ§larÄ± tahmin etmek (distribution drift) performans kaybÄ±na yol aÃ§abilir.\n",
        "- Random split ile model her yÄ±ldan (Ã¶zellikle gÃ¼ncel yÄ±llardan da) veri gÃ¶rerek eÄŸitilmiÅŸ olur.\n",
        "\n",
        "**Split OranlarÄ±:**\n",
        "- Train: %70\n",
        "- Validation: %15\n",
        "- Test: %15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tarih AralÄ±ÄŸÄ± Analizi:\n",
            "\n",
            "Min tarih: 2010-10-26 00:00:00\n",
            "Max tarih: 2025-11-15 00:00:00\n",
            "Toplam gÃ¼n: 5499\n",
            "Toplam maÃ§: 17,832\n",
            "\n",
            "YÄ±llara gÃ¶re maÃ§ sayÄ±sÄ±:\n",
            "  2010: 482\n",
            "  2011: 885\n",
            "  2012: 1,474\n",
            "  2013: 1,324\n",
            "  2014: 1,334\n",
            "  2015: 1,319\n",
            "  2016: 1,333\n",
            "  2017: 1,347\n",
            "  2018: 1,316\n",
            "  2019: 1,267\n",
            "  2020: 706\n",
            "  2021: 1,625\n",
            "  2022: 1,336\n",
            "  2023: 1,248\n",
            "  2024: 824\n",
            "  2025: 12\n"
          ]
        }
      ],
      "source": [
        "# Tarih aralÄ±ÄŸÄ±nÄ± analiz et\n",
        "print(\"Tarih AralÄ±ÄŸÄ± Analizi:\")\n",
        "stats = analyze_date_range(games_with_injury, date_col='game_date')\n",
        "\n",
        "print(f\"\\nMin tarih: {stats['min_date']}\")\n",
        "print(f\"Max tarih: {stats['max_date']}\")\n",
        "print(f\"Toplam gÃ¼n: {stats['date_range_days']}\")\n",
        "print(f\"Toplam maÃ§: {stats['total_games']:,}\")\n",
        "\n",
        "print(f\"\\nYÄ±llara gÃ¶re maÃ§ sayÄ±sÄ±:\")\n",
        "for year, count in sorted(stats['games_per_year'].items()):\n",
        "    print(f\"  {year}: {count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Split KonfigÃ¼rasyonu:\n",
            "  Train:  70%\n",
            "  Val:    15%\n",
            "  Test:   15%\n",
            "  Random State: 30\n"
          ]
        }
      ],
      "source": [
        "# Random Split KonfigÃ¼rasyonu\n",
        "TRAIN_RATIO = 0.70  # %70 Train\n",
        "VAL_RATIO = 0.15    # %15 Validation  \n",
        "TEST_RATIO = 0.15   # %15 Test\n",
        "RANDOM_STATE = 30   # Reproducibility iÃ§in\n",
        "\n",
        "print(f\"Random Split KonfigÃ¼rasyonu:\")\n",
        "print(f\"  Train:  {TRAIN_RATIO:.0%}\")\n",
        "print(f\"  Val:    {VAL_RATIO:.0%}\")\n",
        "print(f\"  Test:   {TEST_RATIO:.0%}\")\n",
        "print(f\"  Random State: {RANDOM_STATE}\")\n",
        "\n",
        "# Not: Eski zaman bazlÄ± split iÃ§in suggest_split_dates kullanÄ±labilir:\n",
        "# suggested_train_end, suggested_val_end = suggest_split_dates(\n",
        "#     games_with_injury,\n",
        "#     date_col='game_date',\n",
        "#     train_ratio=0.70,\n",
        "#     val_ratio=0.15\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toplam maÃ§ sayÄ±sÄ±: 17,832\n",
            "\n",
            "Beklenen split sonuÃ§larÄ±:\n",
            "  Train: ~12,482 maÃ§\n",
            "  Val:   ~2,674 maÃ§\n",
            "  Test:  ~2,674 maÃ§\n"
          ]
        }
      ],
      "source": [
        "# Veri Ã¶zeti\n",
        "print(f\"Toplam maÃ§ sayÄ±sÄ±: {len(games_with_injury):,}\")\n",
        "print(f\"\\nBeklenen split sonuÃ§larÄ±:\")\n",
        "print(f\"  Train: ~{int(len(games_with_injury) * TRAIN_RATIO):,} maÃ§\")\n",
        "print(f\"  Val:   ~{int(len(games_with_injury) * VAL_RATIO):,} maÃ§\")\n",
        "print(f\"  Test:  ~{int(len(games_with_injury) * TEST_RATIO):,} maÃ§\")\n",
        "\n",
        "# Not: Eski zaman bazlÄ± split iÃ§in:\n",
        "# TRAIN_END = \"2021-07-01\"\n",
        "# VAL_END = \"2023-07-01\"\n",
        "# TEST_END = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "RANDOM SPLIT Ä°STATÄ°STÄ°KLERÄ°\n",
            "============================================================\n",
            "\n",
            "Train:\n",
            "  MaÃ§ sayÄ±sÄ±: 12,482 (70.0%)\n",
            "  Tarih aralÄ±ÄŸÄ±: 2010-10-26 - 2025-11-12\n",
            "  YÄ±l daÄŸÄ±lÄ±mÄ±: 2010: 342, 2011: 627, 2012: 1043, 2013: 937, 2014: 958, 2015: 917, 2016: 928, 2017: 941, 2018: 927, 2019: 893, 2020: 492, 2021: 1126, 2022: 918, 2023: 867, 2024: 557, 2025: 9\n",
            "  Home win rate: 57.6%\n",
            "\n",
            "Val:\n",
            "  MaÃ§ sayÄ±sÄ±: 2,675 (15.0%)\n",
            "  Tarih aralÄ±ÄŸÄ±: 2010-10-26 - 2025-11-15\n",
            "  YÄ±l daÄŸÄ±lÄ±mÄ±: 2010: 62, 2011: 143, 2012: 216, 2013: 183, 2014: 187, 2015: 209, 2016: 204, 2017: 197, 2018: 173, 2019: 184, 2020: 112, 2021: 264, 2022: 222, 2023: 186, 2024: 131, 2025: 2\n",
            "  Home win rate: 56.9%\n",
            "\n",
            "Test:\n",
            "  MaÃ§ sayÄ±sÄ±: 2,675 (15.0%)\n",
            "  Tarih aralÄ±ÄŸÄ±: 2010-10-27 - 2025-10-23\n",
            "  YÄ±l daÄŸÄ±lÄ±mÄ±: 2010: 78, 2011: 115, 2012: 215, 2013: 204, 2014: 189, 2015: 193, 2016: 201, 2017: 209, 2018: 216, 2019: 190, 2020: 102, 2021: 235, 2022: 196, 2023: 195, 2024: 136, 2025: 1\n",
            "  Home win rate: 55.9%\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Random Split yap\n",
        "train_df, val_df, test_df = split_dataset_random(\n",
        "    games_with_injury,\n",
        "    train_ratio=TRAIN_RATIO,\n",
        "    val_ratio=VAL_RATIO,\n",
        "    test_ratio=TEST_RATIO,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Ä°statistikleri gÃ¶ster (yÄ±l daÄŸÄ±lÄ±mÄ± ile)\n",
        "print_split_stats_random(train_df, val_df, test_df, date_col='game_date', label_col='home_team_win')\n",
        "\n",
        "# Not: Eski zaman bazlÄ± split iÃ§in:\n",
        "# train_df, val_df, test_df = split_dataset_by_time(\n",
        "#     games_with_injury,\n",
        "#     train_end=TRAIN_END,\n",
        "#     val_end=VAL_END,\n",
        "#     test_end=TEST_END,\n",
        "#     date_col='game_date'\n",
        "# )\n",
        "# print_split_stats(train_df, val_df, test_df, date_col='game_date', label_col='home_team_win')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… TÃ¼m validation kontrolleri baÅŸarÄ±lÄ±!\n"
          ]
        }
      ],
      "source": [
        "# Validation kontrolleri\n",
        "required_cols = ['home_team_win', 'score_diff', 'game_date', 'home_team', 'away_team']\n",
        "\n",
        "is_valid = validate_splits(\n",
        "    train_df, val_df, test_df,\n",
        "    date_col='game_date',\n",
        "    required_cols=required_cols,\n",
        "    check_date_overlap=False  # Random split iÃ§in tarih overlap kontrolÃ¼ kapalÄ±\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Kaydedilen dosyalar:\n",
            "  train: data_processed\\train_set.csv (12,482 satÄ±r)\n",
            "  val: data_processed\\val_set.csv (2,675 satÄ±r)\n",
            "  test: data_processed\\test_set.csv (2,675 satÄ±r)\n"
          ]
        }
      ],
      "source": [
        "# Split dosyalarÄ±nÄ± kaydet\n",
        "paths = save_splits(\n",
        "    train_df, val_df, test_df,\n",
        "    output_dir='data_processed/',\n",
        "    prefix=''\n",
        ")\n",
        "\n",
        "print(\"\\nKaydedilen dosyalar:\")\n",
        "for name, path in paths.items():\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"  {name}: {path} ({len(df):,} satÄ±r)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Final Verification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Ã‡IKTI DOSYALARI KONTROLÃœ\n",
            "============================================================\n",
            "\n",
            "[X] data_interim/injury_reports_clean.csv bulunamadÄ±!\n",
            "\n",
            "[OK] data_processed/games_with_all_features.csv\n",
            "     SatÄ±r: 17,832, Kolon: 225\n",
            "\n",
            "[OK] data_processed/train_set.csv\n",
            "     SatÄ±r: 12,482, Kolon: 225\n",
            "\n",
            "[OK] data_processed/val_set.csv\n",
            "     SatÄ±r: 2,675, Kolon: 225\n",
            "\n",
            "[OK] data_processed/test_set.csv\n",
            "     SatÄ±r: 2,675, Kolon: 225\n"
          ]
        }
      ],
      "source": [
        "# TÃ¼m Ã§Ä±ktÄ± dosyalarÄ±nÄ± kontrol et\n",
        "output_files = [\n",
        "    \"data_interim/injury_reports_clean.csv\",\n",
        "    \"data_processed/games_with_all_features.csv\",\n",
        "    \"data_processed/train_set.csv\",\n",
        "    \"data_processed/val_set.csv\",\n",
        "    \"data_processed/test_set.csv\"\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Ã‡IKTI DOSYALARI KONTROLÃœ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for file_path in output_files:\n",
        "    path = Path(file_path)\n",
        "    if path.exists():\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"\\n[OK] {file_path}\")\n",
        "        print(f\"     SatÄ±r: {len(df):,}, Kolon: {len(df.columns)}\")\n",
        "    else:\n",
        "        print(f\"\\n[X] {file_path} bulunamadÄ±!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "OVERLAP KONTROLÃœ\n",
            "============================================================\n",
            "\n",
            "Train: 2010-10-26 00:00:00 - 2025-11-12 00:00:00\n",
            "Val:   2010-10-26 00:00:00 - 2025-11-15 00:00:00\n",
            "Test:  2010-10-27 00:00:00 - 2025-10-23 00:00:00\n",
            "\n",
            "[X] Train-Val overlap var!\n",
            "[X] Val-Test overlap var!\n"
          ]
        }
      ],
      "source": [
        "# Train/Val/Test overlap kontrolÃ¼\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"OVERLAP KONTROLÃœ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_dates = pd.to_datetime(train_df['game_date'])\n",
        "val_dates = pd.to_datetime(val_df['game_date'])\n",
        "test_dates = pd.to_datetime(test_df['game_date'])\n",
        "\n",
        "print(f\"\\nTrain: {train_dates.min()} - {train_dates.max()}\")\n",
        "print(f\"Val:   {val_dates.min()} - {val_dates.max()}\")\n",
        "print(f\"Test:  {test_dates.min()} - {test_dates.max()}\")\n",
        "\n",
        "# Overlap var mÄ±?\n",
        "train_val_overlap = train_dates.max() >= val_dates.min()\n",
        "val_test_overlap = val_dates.max() >= test_dates.min()\n",
        "\n",
        "if train_val_overlap:\n",
        "    print(\"\\n[X] Train-Val overlap var!\")\n",
        "else:\n",
        "    print(\"\\n[OK] Train-Val overlap yok\")\n",
        "\n",
        "if val_test_overlap:\n",
        "    print(\"[X] Val-Test overlap var!\")\n",
        "else:\n",
        "    print(\"[OK] Val-Test overlap yok\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LABEL DAÄžILIMI\n",
            "============================================================\n",
            "\n",
            "Train: Home win rate = 57.6%\n",
            "       Score diff = 2.46 +/- 13.99\n",
            "\n",
            "Val: Home win rate = 56.9%\n",
            "       Score diff = 2.35 +/- 13.98\n",
            "\n",
            "Test: Home win rate = 55.9%\n",
            "       Score diff = 1.76 +/- 14.20\n"
          ]
        }
      ],
      "source": [
        "# Label daÄŸÄ±lÄ±mÄ± kontrolÃ¼\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LABEL DAÄžILIMI\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for name, df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
        "    if 'home_team_win' in df.columns:\n",
        "        win_rate = df['home_team_win'].mean() * 100\n",
        "        print(f\"\\n{name}: Home win rate = {win_rate:.1f}%\")\n",
        "    \n",
        "    if 'score_diff' in df.columns:\n",
        "        avg_diff = df['score_diff'].mean()\n",
        "        std_diff = df['score_diff'].std()\n",
        "        print(f\"       Score diff = {avg_diff:.2f} +/- {std_diff:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Bu notebook'un Ã¼rettiÄŸi dosyalar:\n",
        "\n",
        "| Dosya | AÃ§Ä±klama |\n",
        "|-------|----------|\n",
        "| `data_interim/injury_reports_clean.csv` | TemizlenmiÅŸ injury verileri |\n",
        "| `data_processed/games_with_all_features.csv` | Core + Injury features |\n",
        "| `data_processed/train_set.csv` | Training seti |\n",
        "| `data_processed/val_set.csv` | Validation seti |\n",
        "| `data_processed/test_set.csv` | Test seti |\n",
        "\n",
        "Ä°brahim bu dosyalarÄ± model eÄŸitiminde kullanabilir:\n",
        "- `train_set.csv`: Model eÄŸitimi iÃ§in\n",
        "- `val_set.csv`: Hiperparametre optimizasyonu iÃ§in\n",
        "- `test_set.csv`: Final deÄŸerlendirme iÃ§in\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TÃœM Ä°ÅžLEMLER TAMAMLANDI!\n",
            "============================================================\n",
            "\n",
            "Ä°brahim iÃ§in hazÄ±r dosyalar:\n",
            "  - data_processed/train_set.csv\n",
            "  - data_processed/val_set.csv\n",
            "  - data_processed/test_set.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TÃœM Ä°ÅžLEMLER TAMAMLANDI!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nÄ°brahim iÃ§in hazÄ±r dosyalar:\")\n",
        "print(\"  - data_processed/train_set.csv\")\n",
        "print(\"  - data_processed/val_set.csv\")\n",
        "print(\"  - data_processed/test_set.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
