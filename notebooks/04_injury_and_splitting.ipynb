{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Injury Features & Dataset Splitting\n",
        "\n",
        "Bu notebook, Ekin'in sorumluluƒüundaki g√∂revleri ger√ßekle≈ütirir:\n",
        "\n",
        "1. **Injury Data Processing**: Raw injury verilerini temizle ve birle≈ütir\n",
        "2. **Injury Feature Generation**: Ma√ß bazlƒ± injury feature'larƒ±nƒ± √ºret\n",
        "3. **Final Dataset**: Core features + injury features ile final dataset olu≈ütur\n",
        "4. **Train/Val/Test Split**: Zaman bazlƒ± split yap\n",
        "\n",
        "## Input Dosyalar\n",
        "- `data_interim/games_with_core_features.csv` (ƒ∞brahim'den)\n",
        "- `data_raw/injury_reports_raw/` (Raw injury PDF'lerden parse edilmi≈ü CSV'ler)\n",
        "- `data_raw/nbastuffer_2025_2026_player_stats_raw.csv` (Oyuncu dakika bilgileri)\n",
        "\n",
        "## Output Dosyalar\n",
        "- `data_interim/injury_reports_clean.csv` (Temizlenmi≈ü injury verileri)\n",
        "- `data_processed/games_with_all_features.csv` (Core + injury features)\n",
        "- `data_processed/train_set.csv`\n",
        "- `data_processed/val_set.csv`\n",
        "- `data_processed/test_set.csv`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proje root: c:\\Users\\Esref\\OneDrive\\Masa√ºst√º\\ann\n",
            "√áalƒ±≈üma dizini: c:\\Users\\Esref\\OneDrive\\Masa√ºst√º\\ann\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Proje root dizinini bul\n",
        "project_root = Path().absolute().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# √áalƒ±≈üma dizinini proje root'una ayarla\n",
        "os.chdir(project_root)\n",
        "\n",
        "print(f\"Proje root: {project_root}\")\n",
        "print(f\"√áalƒ±≈üma dizini: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mod√ºller y√ºklendi!\n"
          ]
        }
      ],
      "source": [
        "# Mod√ºlleri import et\n",
        "from src.features.injury_features import (\n",
        "    load_and_clean_injury_reports,\n",
        "    load_player_minutes,\n",
        "    add_injury_features,\n",
        "    build_injury_features\n",
        ")\n",
        "\n",
        "from src.data.split_dataset import (\n",
        "    analyze_date_range,\n",
        "    split_dataset_by_time,\n",
        "    split_dataset_random,\n",
        "    save_splits,\n",
        "    print_split_stats,\n",
        "    print_split_stats_random,\n",
        "    validate_splits,\n",
        "    create_time_based_split,\n",
        "    create_random_split,\n",
        "    suggest_split_dates\n",
        ")\n",
        "\n",
        "print(\"Mod√ºller y√ºklendi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Core Features Dosyasƒ±nƒ± Kontrol Et\n",
        "\n",
        "ƒ∞brahim'in build_features.py pipeline'ƒ±nƒ±n √ßƒ±ktƒ±sƒ±nƒ± kontrol edelim. Eƒüer yoksa, olu≈üturalƒ±m.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "master_merged.csv mevcut: data_processed\\master_merged.csv\n",
            "Core features mevcut: data_interim\\games_with_core_features.csv\n"
          ]
        }
      ],
      "source": [
        "# ƒ∞lk olarak ƒ∞brahim'in pipeline'ƒ±nƒ± √ßalƒ±≈ütƒ±rƒ±p core features'ƒ± √ºretelim\n",
        "from src.features.build_features import build_model_dataset\n",
        "\n",
        "# master_merged.csv yoksa, √∂nce onu olu≈üturmamƒ±z gerekiyor\n",
        "master_csv = Path(\"data_processed/master_merged.csv\")\n",
        "\n",
        "if not master_csv.exists():\n",
        "    print(\"master_merged.csv bulunamadƒ±!\")\n",
        "    print(\"√ñnce 02_clean_merge.ipynb notebook'unu √ßalƒ±≈ütƒ±rƒ±n.\")\n",
        "else:\n",
        "    print(f\"master_merged.csv mevcut: {master_csv}\")\n",
        "    \n",
        "    # Core features'ƒ± olu≈ütur\n",
        "    core_features_path = Path(\"data_interim/games_with_core_features.csv\")\n",
        "    if not core_features_path.exists():\n",
        "        print(\"\\nCore features olu≈üturuluyor...\")\n",
        "        build_model_dataset(\n",
        "            master_csv=master_csv,\n",
        "            output_csv=\"data_processed/model_dataset.csv\",\n",
        "            write_interim=True\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Core features mevcut: {core_features_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core Features:\n",
            "  Satƒ±r sayƒ±sƒ±: 18,226\n",
            "  Kolon sayƒ±sƒ±: 213\n",
            "\n",
            "Kolonlar:\n",
            "  1. gameId\n",
            "  2. game_date\n",
            "  3. season_year\n",
            "  4. home_team\n",
            "  5. away_team\n",
            "  6. home_team_code\n",
            "  7. away_team_code\n",
            "  8. season_type\n",
            "  9. matchup\n",
            "  10. RANK_x\n",
            "  11. home_team_CONF\n",
            "  12. home_team_DIVISION\n",
            "  13. home_team_GP\n",
            "  14. home_team_PPG\n",
            "  15. home_team_oPPG\n",
            "  16. home_team_pDIFF\n",
            "  17. home_team_PACE\n",
            "  18. home_team_oEFF\n",
            "  19. home_team_dEFF\n",
            "  20. home_team_eDIFF\n",
            "  21. home_team_SoS\n",
            "  22. home_team_rSoS\n",
            "  23. home_team_SAR\n",
            "  24. home_team_CONS\n",
            "  25. home_team_A4F\n",
            "  26. home_team_W\n",
            "  27. home_team_L\n",
            "  28. home_team_WINpct\n",
            "  29. home_team_eWINpct\n",
            "  30. home_team_pWINpct\n",
            "  31. home_team_ACH\n",
            "  32. home_team_STRK\n",
            "  33. RANK_y\n",
            "  34. away_team_CONF\n",
            "  35. away_team_DIVISION\n",
            "  36. away_team_GP\n",
            "  37. away_team_PPG\n",
            "  38. away_team_oPPG\n",
            "  39. away_team_pDIFF\n",
            "  40. away_team_PACE\n",
            "  41. away_team_oEFF\n",
            "  42. away_team_dEFF\n",
            "  43. away_team_eDIFF\n",
            "  44. away_team_SoS\n",
            "  45. away_team_rSoS\n",
            "  46. away_team_SAR\n",
            "  47. away_team_CONS\n",
            "  48. away_team_A4F\n",
            "  49. away_team_W\n",
            "  50. away_team_L\n",
            "  51. away_team_WINpct\n",
            "  52. away_team_eWINpct\n",
            "  53. away_team_pWINpct\n",
            "  54. away_team_ACH\n",
            "  55. away_team_STRK\n",
            "  56. home_rest_4IN5_B2B_GP\n",
            "  57. home_rest_4IN5_B2B_Wpct\n",
            "  58. home_rest_4IN5_B2B_AED\n",
            "  59. home_rest_3IN4_B2B_GP\n",
            "  60. home_rest_3IN4_B2B_Wpct\n",
            "  61. home_rest_3IN4_B2B_AED\n",
            "  62. home_rest_B2B_GP\n",
            "  63. home_rest_B2B_Wpct\n",
            "  64. home_rest_B2B_AED\n",
            "  65. home_rest_3IN4_GP\n",
            "  66. home_rest_3IN4_Wpct\n",
            "  67. home_rest_3IN4_AED\n",
            "  68. home_rest_1_DAY_GP\n",
            "  69. home_rest_1_DAY_Wpct\n",
            "  70. home_rest_1_DAY_AED\n",
            "  71. home_rest_2_DAYS_GP\n",
            "  72. home_rest_2_DAYS_Wpct\n",
            "  73. home_rest_2_DAYS_AED\n",
            "  74. home_rest_3_DAYS_GP\n",
            "  75. home_rest_3_DAYS_Wpct\n",
            "  76. home_rest_3_DAYS_AED\n",
            "  77. away_rest_4IN5_B2B_GP\n",
            "  78. away_rest_4IN5_B2B_Wpct\n",
            "  79. away_rest_4IN5_B2B_AED\n",
            "  80. away_rest_3IN4_B2B_GP\n",
            "  81. away_rest_3IN4_B2B_Wpct\n",
            "  82. away_rest_3IN4_B2B_AED\n",
            "  83. away_rest_B2B_GP\n",
            "  84. away_rest_B2B_Wpct\n",
            "  85. away_rest_B2B_AED\n",
            "  86. away_rest_3IN4_GP\n",
            "  87. away_rest_3IN4_Wpct\n",
            "  88. away_rest_3IN4_AED\n",
            "  89. away_rest_1_DAY_GP\n",
            "  90. away_rest_1_DAY_Wpct\n",
            "  91. away_rest_1_DAY_AED\n",
            "  92. away_rest_2_DAYS_GP\n",
            "  93. away_rest_2_DAYS_Wpct\n",
            "  94. away_rest_2_DAYS_AED\n",
            "  95. away_rest_3_DAYS_GP\n",
            "  96. away_rest_3_DAYS_Wpct\n",
            "  97. away_rest_3_DAYS_AED\n",
            "  98. home_schedule_TOTAL_GAMES\n",
            "  99. home_schedule_5_IN_7\n",
            "  100. home_schedule_3IN4_B2B\n",
            "  101. home_schedule_SOFT_B2B\n",
            "  102. home_schedule_ALL_B2B\n",
            "  103. home_schedule_TOTAL_B2B_ON_THE_ROAD\n",
            "  104. home_schedule_TOTAL_B2B_AT_HOME\n",
            "  105. home_schedule_3IN4\n",
            "  106. home_schedule_1_DAY_REST\n",
            "  107. home_schedule_2_DAYS_REST\n",
            "  108. home_schedule_3DAYS_REST\n",
            "  109. home_schedule_REST_ADVANTAGE\n",
            "  110. home_schedule_REST_DISADVANTAGE\n",
            "  111. home_schedule_BOTH_TEAMS_RESTED_or_NO_REST\n",
            "  112. away_schedule_TOTAL_GAMES\n",
            "  113. away_schedule_5_IN_7\n",
            "  114. away_schedule_3IN4_B2B\n",
            "  115. away_schedule_SOFT_B2B\n",
            "  116. away_schedule_ALL_B2B\n",
            "  117. away_schedule_TOTAL_B2B_ON_THE_ROAD\n",
            "  118. away_schedule_TOTAL_B2B_AT_HOME\n",
            "  119. away_schedule_3IN4\n",
            "  120. away_schedule_1_DAY_REST\n",
            "  121. away_schedule_2_DAYS_REST\n",
            "  122. away_schedule_3DAYS_REST\n",
            "  123. away_schedule_REST_ADVANTAGE\n",
            "  124. away_schedule_REST_DISADVANTAGE\n",
            "  125. away_schedule_BOTH_TEAMS_RESTED_or_NO_REST\n",
            "  126. month\n",
            "  127. day_of_week\n",
            "  128. is_weekend\n",
            "  129. is_playoff\n",
            "  130. home_team_win\n",
            "  131. score_diff\n",
            "  132. home_elo_before\n",
            "  133. away_elo_before\n",
            "  134. diff_elo\n",
            "  135. home_roll_w5_win_rate\n",
            "  136. home_roll_w5_avg_score_diff\n",
            "  137. home_roll_w5_avg_points_for\n",
            "  138. home_roll_w5_avg_points_against\n",
            "  139. home_roll_w10_win_rate\n",
            "  140. home_roll_w10_avg_score_diff\n",
            "  141. home_roll_w10_avg_points_for\n",
            "  142. home_roll_w10_avg_points_against\n",
            "  143. away_roll_w5_win_rate\n",
            "  144. away_roll_w5_avg_score_diff\n",
            "  145. away_roll_w5_avg_points_for\n",
            "  146. away_roll_w5_avg_points_against\n",
            "  147. away_roll_w10_win_rate\n",
            "  148. away_roll_w10_avg_score_diff\n",
            "  149. away_roll_w10_avg_points_for\n",
            "  150. away_roll_w10_avg_points_against\n",
            "  151. diff_roll_w5_win_rate\n",
            "  152. diff_roll_w5_avg_score_diff\n",
            "  153. diff_roll_w5_avg_points_for\n",
            "  154. diff_roll_w5_avg_points_against\n",
            "  155. diff_roll_w10_win_rate\n",
            "  156. diff_roll_w10_avg_score_diff\n",
            "  157. diff_roll_w10_avg_points_for\n",
            "  158. diff_roll_w10_avg_points_against\n",
            "  159. diff_team_GP\n",
            "  160. diff_team_PPG\n",
            "  161. diff_team_oPPG\n",
            "  162. diff_team_pDIFF\n",
            "  163. diff_team_PACE\n",
            "  164. diff_team_oEFF\n",
            "  165. diff_team_dEFF\n",
            "  166. diff_team_eDIFF\n",
            "  167. diff_team_SoS\n",
            "  168. diff_team_rSoS\n",
            "  169. diff_team_SAR\n",
            "  170. diff_team_CONS\n",
            "  171. diff_team_A4F\n",
            "  172. diff_team_W\n",
            "  173. diff_team_L\n",
            "  174. diff_team_WINpct\n",
            "  175. diff_team_eWINpct\n",
            "  176. diff_team_pWINpct\n",
            "  177. diff_team_ACH\n",
            "  178. diff_team_STRK\n",
            "  179. diff_rest_4IN5_B2B_GP\n",
            "  180. diff_rest_4IN5_B2B_Wpct\n",
            "  181. diff_rest_4IN5_B2B_AED\n",
            "  182. diff_rest_3IN4_B2B_GP\n",
            "  183. diff_rest_3IN4_B2B_Wpct\n",
            "  184. diff_rest_3IN4_B2B_AED\n",
            "  185. diff_rest_B2B_GP\n",
            "  186. diff_rest_B2B_Wpct\n",
            "  187. diff_rest_B2B_AED\n",
            "  188. diff_rest_3IN4_GP\n",
            "  189. diff_rest_3IN4_Wpct\n",
            "  190. diff_rest_3IN4_AED\n",
            "  191. diff_rest_1_DAY_GP\n",
            "  192. diff_rest_1_DAY_Wpct\n",
            "  193. diff_rest_1_DAY_AED\n",
            "  194. diff_rest_2_DAYS_GP\n",
            "  195. diff_rest_2_DAYS_Wpct\n",
            "  196. diff_rest_2_DAYS_AED\n",
            "  197. diff_rest_3_DAYS_GP\n",
            "  198. diff_rest_3_DAYS_Wpct\n",
            "  199. diff_rest_3_DAYS_AED\n",
            "  200. diff_schedule_TOTAL_GAMES\n",
            "  201. diff_schedule_5_IN_7\n",
            "  202. diff_schedule_3IN4_B2B\n",
            "  203. diff_schedule_SOFT_B2B\n",
            "  204. diff_schedule_ALL_B2B\n",
            "  205. diff_schedule_TOTAL_B2B_ON_THE_ROAD\n",
            "  206. diff_schedule_TOTAL_B2B_AT_HOME\n",
            "  207. diff_schedule_3IN4\n",
            "  208. diff_schedule_1_DAY_REST\n",
            "  209. diff_schedule_2_DAYS_REST\n",
            "  210. diff_schedule_3DAYS_REST\n",
            "  211. diff_schedule_REST_ADVANTAGE\n",
            "  212. diff_schedule_REST_DISADVANTAGE\n",
            "  213. diff_schedule_BOTH_TEAMS_RESTED_or_NO_REST\n",
            "\n",
            "ƒ∞lk 3 satƒ±r:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gameId</th>\n",
              "      <th>game_date</th>\n",
              "      <th>season_year</th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>home_team_code</th>\n",
              "      <th>away_team_code</th>\n",
              "      <th>season_type</th>\n",
              "      <th>matchup</th>\n",
              "      <th>RANK_x</th>\n",
              "      <th>...</th>\n",
              "      <th>diff_schedule_ALL_B2B</th>\n",
              "      <th>diff_schedule_TOTAL_B2B_ON_THE_ROAD</th>\n",
              "      <th>diff_schedule_TOTAL_B2B_AT_HOME</th>\n",
              "      <th>diff_schedule_3IN4</th>\n",
              "      <th>diff_schedule_1_DAY_REST</th>\n",
              "      <th>diff_schedule_2_DAYS_REST</th>\n",
              "      <th>diff_schedule_3DAYS_REST</th>\n",
              "      <th>diff_schedule_REST_ADVANTAGE</th>\n",
              "      <th>diff_schedule_REST_DISADVANTAGE</th>\n",
              "      <th>diff_schedule_BOTH_TEAMS_RESTED_or_NO_REST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21000001</td>\n",
              "      <td>2010-10-26</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>Miami Heat</td>\n",
              "      <td>BOS</td>\n",
              "      <td>MIA</td>\n",
              "      <td>regular</td>\n",
              "      <td>BOS vs. MIA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>-5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21000002</td>\n",
              "      <td>2010-10-26</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>Portland Trail Blazers</td>\n",
              "      <td>Phoenix Suns</td>\n",
              "      <td>POR</td>\n",
              "      <td>PHX</td>\n",
              "      <td>regular</td>\n",
              "      <td>PHX @ POR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21000003</td>\n",
              "      <td>2010-10-26</td>\n",
              "      <td>2010-11</td>\n",
              "      <td>Los Angeles Lakers</td>\n",
              "      <td>Houston Rockets</td>\n",
              "      <td>LAL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>regular</td>\n",
              "      <td>HOU @ LAL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows √ó 213 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     gameId   game_date season_year               home_team        away_team  \\\n",
              "0  21000001  2010-10-26     2010-11          Boston Celtics       Miami Heat   \n",
              "1  21000002  2010-10-26     2010-11  Portland Trail Blazers     Phoenix Suns   \n",
              "2  21000003  2010-10-26     2010-11      Los Angeles Lakers  Houston Rockets   \n",
              "\n",
              "  home_team_code away_team_code season_type      matchup  RANK_x  ...  \\\n",
              "0            BOS            MIA     regular  BOS vs. MIA     NaN  ...   \n",
              "1            POR            PHX     regular    PHX @ POR     NaN  ...   \n",
              "2            LAL            HOU     regular    HOU @ LAL     NaN  ...   \n",
              "\n",
              "  diff_schedule_ALL_B2B diff_schedule_TOTAL_B2B_ON_THE_ROAD  \\\n",
              "0                    -2                                   1   \n",
              "1                    -1                                   2   \n",
              "2                     0                                  -2   \n",
              "\n",
              "   diff_schedule_TOTAL_B2B_AT_HOME  diff_schedule_3IN4  \\\n",
              "0                               -3                   0   \n",
              "1                               -3                  -3   \n",
              "2                                2                   1   \n",
              "\n",
              "   diff_schedule_1_DAY_REST  diff_schedule_2_DAYS_REST  \\\n",
              "0                         5                         -5   \n",
              "1                         5                         -1   \n",
              "2                        -1                          0   \n",
              "\n",
              "   diff_schedule_3DAYS_REST  diff_schedule_REST_ADVANTAGE  \\\n",
              "0                         2                             1   \n",
              "1                         0                             3   \n",
              "2                         0                             1   \n",
              "\n",
              "   diff_schedule_REST_DISADVANTAGE  diff_schedule_BOTH_TEAMS_RESTED_or_NO_REST  \n",
              "0                               -2                                           1  \n",
              "1                               -3                                           0  \n",
              "2                                1                                          -2  \n",
              "\n",
              "[3 rows x 213 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tarih aralƒ±ƒüƒ±:\n",
            "  Min: 2010-10-26 00:00:00\n",
            "  Max: 2025-12-19 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Core features dosyasƒ±nƒ± y√ºkle ve incele\n",
        "core_features_path = Path(\"data_interim/games_with_core_features.csv\")\n",
        "\n",
        "if core_features_path.exists():\n",
        "    core_df = pd.read_csv(core_features_path, low_memory=False)\n",
        "    \n",
        "    print(f\"Core Features:\")\n",
        "    print(f\"  Satƒ±r sayƒ±sƒ±: {len(core_df):,}\")\n",
        "    print(f\"  Kolon sayƒ±sƒ±: {len(core_df.columns)}\")\n",
        "    \n",
        "    print(f\"\\nKolonlar:\")\n",
        "    for i, col in enumerate(core_df.columns):\n",
        "        print(f\"  {i+1}. {col}\")\n",
        "    \n",
        "    print(f\"\\nƒ∞lk 3 satƒ±r:\")\n",
        "    display(core_df.head(3))\n",
        "    \n",
        "    # Tarih aralƒ±ƒüƒ±nƒ± kontrol et\n",
        "    if 'game_date' in core_df.columns:\n",
        "        core_df['game_date'] = pd.to_datetime(core_df['game_date'])\n",
        "        print(f\"\\nTarih aralƒ±ƒüƒ±:\")\n",
        "        print(f\"  Min: {core_df['game_date'].min()}\")\n",
        "        print(f\"  Max: {core_df['game_date'].max()}\")\n",
        "else:\n",
        "    print(\"Core features dosyasƒ± bulunamadƒ±!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Injury Data Processing\n",
        "\n",
        "Raw injury verilerini y√ºkle, temizle ve birle≈ütir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Injury raw dosyalarƒ± (1 dosya):\n",
            "  - Injury-Report_2025-11-16_12PM.parsed.csv\n"
          ]
        }
      ],
      "source": [
        "# Raw injury klas√∂r√ºn√º kontrol et\n",
        "injury_raw_dir = Path(\"data_raw/injury_reports_raw\")\n",
        "\n",
        "if injury_raw_dir.exists():\n",
        "    files = list(injury_raw_dir.glob(\"*\"))\n",
        "    print(f\"Injury raw dosyalarƒ± ({len(files)} dosya):\")\n",
        "    for f in files:\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    print(\"Injury raw klas√∂r√º bulunamadƒ±!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Y√ºkleniyor: Injury-Report_2025-11-16_12PM.parsed.csv\n",
            "‚ö†Ô∏è Injury verisi bulunamadƒ± veya parse edilemedi.\n",
            "   ‚Üí ƒ∞brahim'in yakla≈üƒ±mƒ±: Injury olmadan devam edilecek (inference-time'da kullanƒ±lacak)\n"
          ]
        }
      ],
      "source": [
        "# Injury verilerini y√ºkle ve temizle\n",
        "# NOT: Injury verisi sƒ±nƒ±rlƒ± (sadece 1 g√ºnl√ºk), bu y√ºzden opsiyonel\n",
        "try:\n",
        "    injury_df = load_and_clean_injury_reports(\n",
        "        raw_dir=\"data_raw/injury_reports_raw/\",\n",
        "        output_path=\"data_interim/injury_reports_clean.csv\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Injury verisi y√ºklenirken hata: {e}\")\n",
        "    injury_df = pd.DataFrame()\n",
        "\n",
        "if len(injury_df) > 0:\n",
        "    print(f\"\\n‚úÖ Temizlenmi≈ü injury verileri:\")\n",
        "    print(f\"  Satƒ±r sayƒ±sƒ±: {len(injury_df)}\")\n",
        "    print(f\"\\nKolonlar: {list(injury_df.columns)}\")\n",
        "    print(f\"\\nƒ∞lk 10 satƒ±r:\")\n",
        "    display(injury_df.head(10))\n",
        "\n",
        "    print(f\"\\nStatus daƒüƒ±lƒ±mƒ±:\")\n",
        "    print(injury_df['status'].value_counts())\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Injury verisi bulunamadƒ± veya parse edilemedi.\")\n",
        "    print(\"   ‚Üí ƒ∞brahim'in yakla≈üƒ±mƒ±: Injury olmadan devam edilecek (inference-time'da kullanƒ±lacak)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Player Minutes Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Player minutes y√ºklendi: 503 oyuncu\n",
            "\n",
            "‚úÖ Player minutes verileri:\n",
            "  Oyuncu sayƒ±sƒ±: 503\n",
            "\n",
            "En √ßok oynayan oyuncular:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>player_name</th>\n",
              "      <th>team</th>\n",
              "      <th>avg_minutes_per_game</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>Tyrese Maxey</td>\n",
              "      <td>Philadelphia 76ers</td>\n",
              "      <td>39.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>Keegan Murray</td>\n",
              "      <td>Sacramento Kings</td>\n",
              "      <td>37.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Luka Doncic</td>\n",
              "      <td>Los Angeles Lakers</td>\n",
              "      <td>37.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Austin Reaves</td>\n",
              "      <td>Los Angeles Lakers</td>\n",
              "      <td>36.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amen Thompson</td>\n",
              "      <td>Houston Rockets</td>\n",
              "      <td>36.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alperen Sengun</td>\n",
              "      <td>Houston Rockets</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>Cade Cunningham</td>\n",
              "      <td>Detroit Pistons</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kevin Durant</td>\n",
              "      <td>Houston Rockets</td>\n",
              "      <td>36.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>Trey Murphy III</td>\n",
              "      <td>New Orleans Pelicans</td>\n",
              "      <td>35.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>James Harden</td>\n",
              "      <td>LA Clippers</td>\n",
              "      <td>35.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>Lauri Markkanen</td>\n",
              "      <td>Utah Jazz</td>\n",
              "      <td>35.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Jalen Brunson</td>\n",
              "      <td>New York Knicks</td>\n",
              "      <td>35.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Jalen Johnson</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>35.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>VJ Edgecombe</td>\n",
              "      <td>Philadelphia 76ers</td>\n",
              "      <td>35.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>Nikola Jokic</td>\n",
              "      <td>Denver Nuggets</td>\n",
              "      <td>35.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         player_name                  team  avg_minutes_per_game\n",
              "129     Tyrese Maxey    Philadelphia 76ers                  39.8\n",
              "472    Keegan Murray      Sacramento Kings                  37.5\n",
              "35       Luka Doncic    Los Angeles Lakers                  37.4\n",
              "31     Austin Reaves    Los Angeles Lakers                  36.9\n",
              "4      Amen Thompson       Houston Rockets                  36.7\n",
              "1     Alperen Sengun       Houston Rockets                  36.2\n",
              "149  Cade Cunningham       Detroit Pistons                  36.2\n",
              "3       Kevin Durant       Houston Rockets                  36.1\n",
              "165  Trey Murphy III  New Orleans Pelicans                  35.6\n",
              "220     James Harden           LA Clippers                  35.4\n",
              "230  Lauri Markkanen             Utah Jazz                  35.3\n",
              "54     Jalen Brunson       New York Knicks                  35.1\n",
              "116    Jalen Johnson         Atlanta Hawks                  35.1\n",
              "128     VJ Edgecombe    Philadelphia 76ers                  35.1\n",
              "326     Nikola Jokic        Denver Nuggets                  35.1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dakika daƒüƒ±lƒ±mƒ±:\n",
            "count    503.000000\n",
            "mean      19.362425\n",
            "std        9.845941\n",
            "min        0.600000\n",
            "25%       11.200000\n",
            "50%       19.300000\n",
            "75%       28.050000\n",
            "max       39.800000\n",
            "Name: avg_minutes_per_game, dtype: float64\n",
            "\n",
            "Key players (25+ dk): 173 oyuncu\n"
          ]
        }
      ],
      "source": [
        "# Player minutes verilerini y√ºkle (opsiyonel - injury i√ßin gerekli)\n",
        "try:\n",
        "    player_minutes_df = load_player_minutes(\n",
        "        player_stats_path=\"data_raw/nbastuffer_2025_2026_player_stats_raw.csv\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Player minutes y√ºklenirken hata: {e}\")\n",
        "    player_minutes_df = pd.DataFrame()\n",
        "\n",
        "if len(player_minutes_df) > 0:\n",
        "    print(f\"\\n‚úÖ Player minutes verileri:\")\n",
        "    print(f\"  Oyuncu sayƒ±sƒ±: {len(player_minutes_df)}\")\n",
        "\n",
        "    print(f\"\\nEn √ßok oynayan oyuncular:\")\n",
        "    top_players = player_minutes_df.nlargest(15, 'avg_minutes_per_game')\n",
        "    display(top_players)\n",
        "\n",
        "    print(f\"\\nDakika daƒüƒ±lƒ±mƒ±:\")\n",
        "    print(player_minutes_df['avg_minutes_per_game'].describe())\n",
        "\n",
        "    # Key players (25+ dk)\n",
        "    key_players = player_minutes_df[player_minutes_df['avg_minutes_per_game'] >= 25]\n",
        "    print(f\"\\nKey players (25+ dk): {len(key_players)} oyuncu\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Player minutes verisi bulunamadƒ± - Injury features i√ßin gerekli deƒüil\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Injury Features Generation\n",
        "\n",
        "Core features'a injury feature'larƒ±nƒ± ekle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Yeterli injury verisi yok - ƒ∞brahim'in yakla≈üƒ±mƒ± uygulanƒ±yor:\n",
            "   ‚Üí Injury feature'larƒ± 0 olarak ayarlanacak\n",
            "   ‚Üí Model sadece core features ile eƒüitilecek\n",
            "   ‚Üí Injury, inference-time'da ayrƒ± kullanƒ±lacak\n",
            "\n",
            "üìä Final dataset:\n",
            "  Satƒ±r sayƒ±sƒ±: 18,226\n",
            "  Kolon sayƒ±sƒ±: 219\n"
          ]
        }
      ],
      "source": [
        "# Injury features ekle (veya placeholder kullan)\n",
        "if core_features_path.exists():\n",
        "    # Injury verisi varsa ve yeterliyse kullan\n",
        "    if len(injury_df) > 0 and 'player_minutes_df' in dir() and len(player_minutes_df) > 0:\n",
        "        try:\n",
        "            games_with_injury = add_injury_features(\n",
        "                games_df=core_df,\n",
        "                injury_df=injury_df,\n",
        "                player_minutes_df=player_minutes_df,\n",
        "                key_player_minutes_threshold=25.0\n",
        "            )\n",
        "            print(f\"\\n‚úÖ Injury features eklendi:\")\n",
        "            new_cols = [col for col in games_with_injury.columns if col not in core_df.columns]\n",
        "            print(f\"  Yeni kolonlar: {new_cols}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Injury features eklenirken hata: {e}\")\n",
        "            games_with_injury = core_df.copy()\n",
        "    else:\n",
        "        # ƒ∞brahim'in yakla≈üƒ±mƒ±: Injury verisi yetersiz, placeholder kullan\n",
        "        print(\"‚ö†Ô∏è Yeterli injury verisi yok - ƒ∞brahim'in yakla≈üƒ±mƒ± uygulanƒ±yor:\")\n",
        "        print(\"   ‚Üí Injury feature'larƒ± 0 olarak ayarlanacak\")\n",
        "        print(\"   ‚Üí Model sadece core features ile eƒüitilecek\")\n",
        "        print(\"   ‚Üí Injury, inference-time'da ayrƒ± kullanƒ±lacak\")\n",
        "        \n",
        "        games_with_injury = core_df.copy()\n",
        "        # Placeholder injury kolonlarƒ± (hepsi 0)\n",
        "        games_with_injury['injury_count_home'] = 0\n",
        "        games_with_injury['injury_count_away'] = 0\n",
        "        games_with_injury['expected_minutes_lost_home'] = 0.0\n",
        "        games_with_injury['expected_minutes_lost_away'] = 0.0\n",
        "        games_with_injury['any_key_player_out_home'] = 0\n",
        "        games_with_injury['any_key_player_out_away'] = 0\n",
        "\n",
        "    print(f\"\\nüìä Final dataset:\")\n",
        "    print(f\"  Satƒ±r sayƒ±sƒ±: {len(games_with_injury):,}\")\n",
        "    print(f\"  Kolon sayƒ±sƒ±: {len(games_with_injury.columns)}\")\n",
        "else:\n",
        "    print(\"‚ùå Core features dosyasƒ± bulunamadƒ±!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset kaydedildi: data_processed\\games_with_all_features.csv\n",
            "   18,226 satƒ±r, 219 kolon\n"
          ]
        }
      ],
      "source": [
        "# Final dataset'i kaydet\n",
        "output_path = Path(\"data_processed/games_with_all_features.csv\")\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "games_with_injury.to_csv(output_path, index=False)\n",
        "print(f\"Final dataset kaydedildi: {output_path}\")\n",
        "print(f\"   {len(games_with_injury):,} satƒ±r, {len(games_with_injury.columns)} kolon\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Dataset Splitting (Random Shuffle)\n",
        "\n",
        "Rastgele karƒ±≈ütƒ±rmalƒ± (random shuffle) train/val/test split yap.\n",
        "\n",
        "**Neden Random Split?**\n",
        "- Basketbolun oyun yapƒ±sƒ± yƒ±llar i√ßinde deƒüi≈ütiƒüi i√ßin, sadece eski verilerle eƒüitilip g√ºncel ma√ßlarƒ± tahmin etmek (distribution drift) performans kaybƒ±na yol a√ßabilir.\n",
        "- Random split ile model her yƒ±ldan (√∂zellikle g√ºncel yƒ±llardan da) veri g√∂rerek eƒüitilmi≈ü olur.\n",
        "\n",
        "**Split Oranlarƒ±:**\n",
        "- Train: %70\n",
        "- Validation: %15\n",
        "- Test: %15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tarih Aralƒ±ƒüƒ± Analizi:\n",
            "\n",
            "Min tarih: 2010-10-26 00:00:00\n",
            "Max tarih: 2025-12-19 00:00:00\n",
            "Toplam g√ºn: 5533\n",
            "Toplam ma√ß: 18,226\n",
            "\n",
            "Yƒ±llara g√∂re ma√ß sayƒ±sƒ±:\n",
            "  2010: 482\n",
            "  2011: 885\n",
            "  2012: 1,474\n",
            "  2013: 1,324\n",
            "  2014: 1,334\n",
            "  2015: 1,319\n",
            "  2016: 1,333\n",
            "  2017: 1,347\n",
            "  2018: 1,316\n",
            "  2019: 1,267\n",
            "  2020: 706\n",
            "  2021: 1,625\n",
            "  2022: 1,336\n",
            "  2023: 1,248\n",
            "  2024: 824\n",
            "  2025: 406\n"
          ]
        }
      ],
      "source": [
        "# Tarih aralƒ±ƒüƒ±nƒ± analiz et\n",
        "print(\"Tarih Aralƒ±ƒüƒ± Analizi:\")\n",
        "stats = analyze_date_range(games_with_injury, date_col='game_date')\n",
        "\n",
        "print(f\"\\nMin tarih: {stats['min_date']}\")\n",
        "print(f\"Max tarih: {stats['max_date']}\")\n",
        "print(f\"Toplam g√ºn: {stats['date_range_days']}\")\n",
        "print(f\"Toplam ma√ß: {stats['total_games']:,}\")\n",
        "\n",
        "print(f\"\\nYƒ±llara g√∂re ma√ß sayƒ±sƒ±:\")\n",
        "for year, count in sorted(stats['games_per_year'].items()):\n",
        "    print(f\"  {year}: {count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Split Konfig√ºrasyonu:\n",
            "  Train:  70%\n",
            "  Val:    15%\n",
            "  Test:   15%\n",
            "  Random State: 42\n"
          ]
        }
      ],
      "source": [
        "# Random Split Konfig√ºrasyonu\n",
        "TRAIN_RATIO = 0.70  # %70 Train\n",
        "VAL_RATIO = 0.15    # %15 Validation  \n",
        "TEST_RATIO = 0.15   # %15 Test\n",
        "RANDOM_STATE = 42   # Reproducibility i√ßin\n",
        "\n",
        "print(f\"Random Split Konfig√ºrasyonu:\")\n",
        "print(f\"  Train:  {TRAIN_RATIO:.0%}\")\n",
        "print(f\"  Val:    {VAL_RATIO:.0%}\")\n",
        "print(f\"  Test:   {TEST_RATIO:.0%}\")\n",
        "print(f\"  Random State: {RANDOM_STATE}\")\n",
        "\n",
        "# Not: Eski zaman bazlƒ± split i√ßin suggest_split_dates kullanƒ±labilir:\n",
        "# suggested_train_end, suggested_val_end = suggest_split_dates(\n",
        "#     games_with_injury,\n",
        "#     date_col='game_date',\n",
        "#     train_ratio=0.70,\n",
        "#     val_ratio=0.15\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toplam ma√ß sayƒ±sƒ±: 18,226\n",
            "\n",
            "Beklenen split sonu√ßlarƒ±:\n",
            "  Train: ~12,758 ma√ß\n",
            "  Val:   ~2,733 ma√ß\n",
            "  Test:  ~2,733 ma√ß\n"
          ]
        }
      ],
      "source": [
        "# Veri √∂zeti\n",
        "print(f\"Toplam ma√ß sayƒ±sƒ±: {len(games_with_injury):,}\")\n",
        "print(f\"\\nBeklenen split sonu√ßlarƒ±:\")\n",
        "print(f\"  Train: ~{int(len(games_with_injury) * TRAIN_RATIO):,} ma√ß\")\n",
        "print(f\"  Val:   ~{int(len(games_with_injury) * VAL_RATIO):,} ma√ß\")\n",
        "print(f\"  Test:  ~{int(len(games_with_injury) * TEST_RATIO):,} ma√ß\")\n",
        "\n",
        "# Not: Eski zaman bazlƒ± split i√ßin:\n",
        "# TRAIN_END = \"2021-07-01\"\n",
        "# VAL_END = \"2023-07-01\"\n",
        "# TEST_END = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "RANDOM SPLIT ƒ∞STATƒ∞STƒ∞KLERƒ∞\n",
            "============================================================\n",
            "\n",
            "Train:\n",
            "  Ma√ß sayƒ±sƒ±: 12,758 (70.0%)\n",
            "  Tarih aralƒ±ƒüƒ±: 2010-10-26 - 2025-12-19\n",
            "  Yƒ±l daƒüƒ±lƒ±mƒ±: 2010: 327, 2011: 642, 2012: 1040, 2013: 927, 2014: 932, 2015: 929, 2016: 910, 2017: 954, 2018: 903, 2019: 881, 2020: 476, 2021: 1155, 2022: 942, 2023: 873, 2024: 589, 2025: 278\n",
            "  Home win rate: 57.0%\n",
            "\n",
            "Val:\n",
            "  Ma√ß sayƒ±sƒ±: 2,734 (15.0%)\n",
            "  Tarih aralƒ±ƒüƒ±: 2010-10-26 - 2025-12-19\n",
            "  Yƒ±l daƒüƒ±lƒ±mƒ±: 2010: 91, 2011: 128, 2012: 224, 2013: 190, 2014: 217, 2015: 183, 2016: 208, 2017: 193, 2018: 212, 2019: 207, 2020: 116, 2021: 219, 2022: 200, 2023: 163, 2024: 122, 2025: 61\n",
            "  Home win rate: 58.2%\n",
            "\n",
            "Test:\n",
            "  Ma√ß sayƒ±sƒ±: 2,734 (15.0%)\n",
            "  Tarih aralƒ±ƒüƒ±: 2010-10-27 - 2025-12-19\n",
            "  Yƒ±l daƒüƒ±lƒ±mƒ±: 2010: 64, 2011: 115, 2012: 210, 2013: 207, 2014: 185, 2015: 207, 2016: 215, 2017: 200, 2018: 201, 2019: 179, 2020: 114, 2021: 251, 2022: 194, 2023: 212, 2024: 113, 2025: 67\n",
            "  Home win rate: 56.9%\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Random Split yap\n",
        "train_df, val_df, test_df = split_dataset_random(\n",
        "    games_with_injury,\n",
        "    train_ratio=TRAIN_RATIO,\n",
        "    val_ratio=VAL_RATIO,\n",
        "    test_ratio=TEST_RATIO,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# ƒ∞statistikleri g√∂ster (yƒ±l daƒüƒ±lƒ±mƒ± ile)\n",
        "print_split_stats_random(train_df, val_df, test_df, date_col='game_date', label_col='home_team_win')\n",
        "\n",
        "# Not: Eski zaman bazlƒ± split i√ßin:\n",
        "# train_df, val_df, test_df = split_dataset_by_time(\n",
        "#     games_with_injury,\n",
        "#     train_end=TRAIN_END,\n",
        "#     val_end=VAL_END,\n",
        "#     test_end=TEST_END,\n",
        "#     date_col='game_date'\n",
        "# )\n",
        "# print_split_stats(train_df, val_df, test_df, date_col='game_date', label_col='home_team_win')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ T√ºm validation kontrolleri ba≈üarƒ±lƒ±!\n"
          ]
        }
      ],
      "source": [
        "# Validation kontrolleri\n",
        "required_cols = ['home_team_win', 'score_diff', 'game_date', 'home_team', 'away_team']\n",
        "\n",
        "is_valid = validate_splits(\n",
        "    train_df, val_df, test_df,\n",
        "    date_col='game_date',\n",
        "    required_cols=required_cols,\n",
        "    check_date_overlap=False  # Random split i√ßin tarih overlap kontrol√º kapalƒ±\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Kaydedilen dosyalar:\n",
            "  train: data_processed\\train_set.csv (12,758 satƒ±r)\n",
            "  val: data_processed\\val_set.csv (2,734 satƒ±r)\n",
            "  test: data_processed\\test_set.csv (2,734 satƒ±r)\n"
          ]
        }
      ],
      "source": [
        "# Split dosyalarƒ±nƒ± kaydet\n",
        "paths = save_splits(\n",
        "    train_df, val_df, test_df,\n",
        "    output_dir='data_processed/',\n",
        "    prefix=''\n",
        ")\n",
        "\n",
        "print(\"\\nKaydedilen dosyalar:\")\n",
        "for name, path in paths.items():\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"  {name}: {path} ({len(df):,} satƒ±r)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Final Verification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "√áIKTI DOSYALARI KONTROL√ú\n",
            "============================================================\n",
            "\n",
            "[X] data_interim/injury_reports_clean.csv bulunamadƒ±!\n",
            "\n",
            "[OK] data_processed/games_with_all_features.csv\n",
            "     Satƒ±r: 18,226, Kolon: 219\n",
            "\n",
            "[OK] data_processed/train_set.csv\n",
            "     Satƒ±r: 12,758, Kolon: 219\n",
            "\n",
            "[OK] data_processed/val_set.csv\n",
            "     Satƒ±r: 2,734, Kolon: 219\n",
            "\n",
            "[OK] data_processed/test_set.csv\n",
            "     Satƒ±r: 2,734, Kolon: 219\n"
          ]
        }
      ],
      "source": [
        "# T√ºm √ßƒ±ktƒ± dosyalarƒ±nƒ± kontrol et\n",
        "output_files = [\n",
        "    \"data_interim/injury_reports_clean.csv\",\n",
        "    \"data_processed/games_with_all_features.csv\",\n",
        "    \"data_processed/train_set.csv\",\n",
        "    \"data_processed/val_set.csv\",\n",
        "    \"data_processed/test_set.csv\"\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"√áIKTI DOSYALARI KONTROL√ú\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for file_path in output_files:\n",
        "    path = Path(file_path)\n",
        "    if path.exists():\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"\\n[OK] {file_path}\")\n",
        "        print(f\"     Satƒ±r: {len(df):,}, Kolon: {len(df.columns)}\")\n",
        "    else:\n",
        "        print(f\"\\n[X] {file_path} bulunamadƒ±!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "OVERLAP KONTROL√ú\n",
            "============================================================\n",
            "\n",
            "Train: 2010-10-26 00:00:00 - 2025-12-19 00:00:00\n",
            "Val:   2010-10-26 00:00:00 - 2025-12-19 00:00:00\n",
            "Test:  2010-10-27 00:00:00 - 2025-12-19 00:00:00\n",
            "\n",
            "[X] Train-Val overlap var!\n",
            "[X] Val-Test overlap var!\n"
          ]
        }
      ],
      "source": [
        "# Train/Val/Test overlap kontrol√º\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"OVERLAP KONTROL√ú\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_dates = pd.to_datetime(train_df['game_date'])\n",
        "val_dates = pd.to_datetime(val_df['game_date'])\n",
        "test_dates = pd.to_datetime(test_df['game_date'])\n",
        "\n",
        "print(f\"\\nTrain: {train_dates.min()} - {train_dates.max()}\")\n",
        "print(f\"Val:   {val_dates.min()} - {val_dates.max()}\")\n",
        "print(f\"Test:  {test_dates.min()} - {test_dates.max()}\")\n",
        "\n",
        "# Overlap var mƒ±?\n",
        "train_val_overlap = train_dates.max() >= val_dates.min()\n",
        "val_test_overlap = val_dates.max() >= test_dates.min()\n",
        "\n",
        "if train_val_overlap:\n",
        "    print(\"\\n[X] Train-Val overlap var!\")\n",
        "else:\n",
        "    print(\"\\n[OK] Train-Val overlap yok\")\n",
        "\n",
        "if val_test_overlap:\n",
        "    print(\"[X] Val-Test overlap var!\")\n",
        "else:\n",
        "    print(\"[OK] Val-Test overlap yok\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LABEL DAƒûILIMI\n",
            "============================================================\n",
            "\n",
            "Train: Home win rate = 57.0%\n",
            "       Score diff = 2.32 +/- 14.11\n",
            "\n",
            "Val: Home win rate = 58.2%\n",
            "       Score diff = 2.50 +/- 13.82\n",
            "\n",
            "Test: Home win rate = 56.9%\n",
            "       Score diff = 2.14 +/- 14.00\n"
          ]
        }
      ],
      "source": [
        "# Label daƒüƒ±lƒ±mƒ± kontrol√º\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LABEL DAƒûILIMI\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for name, df in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
        "    if 'home_team_win' in df.columns:\n",
        "        win_rate = df['home_team_win'].mean() * 100\n",
        "        print(f\"\\n{name}: Home win rate = {win_rate:.1f}%\")\n",
        "    \n",
        "    if 'score_diff' in df.columns:\n",
        "        avg_diff = df['score_diff'].mean()\n",
        "        std_diff = df['score_diff'].std()\n",
        "        print(f\"       Score diff = {avg_diff:.2f} +/- {std_diff:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Bu notebook'un √ºrettiƒüi dosyalar:\n",
        "\n",
        "| Dosya | A√ßƒ±klama |\n",
        "|-------|----------|\n",
        "| `data_interim/injury_reports_clean.csv` | Temizlenmi≈ü injury verileri |\n",
        "| `data_processed/games_with_all_features.csv` | Core + Injury features |\n",
        "| `data_processed/train_set.csv` | Training seti |\n",
        "| `data_processed/val_set.csv` | Validation seti |\n",
        "| `data_processed/test_set.csv` | Test seti |\n",
        "\n",
        "ƒ∞brahim bu dosyalarƒ± model eƒüitiminde kullanabilir:\n",
        "- `train_set.csv`: Model eƒüitimi i√ßin\n",
        "- `val_set.csv`: Hiperparametre optimizasyonu i√ßin\n",
        "- `test_set.csv`: Final deƒüerlendirme i√ßin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "T√úM ƒ∞≈ûLEMLER TAMAMLANDI!\n",
            "============================================================\n",
            "\n",
            "ƒ∞brahim i√ßin hazƒ±r dosyalar:\n",
            "  - data_processed/train_set.csv\n",
            "  - data_processed/val_set.csv\n",
            "  - data_processed/test_set.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"T√úM ƒ∞≈ûLEMLER TAMAMLANDI!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nƒ∞brahim i√ßin hazƒ±r dosyalar:\")\n",
        "print(\"  - data_processed/train_set.csv\")\n",
        "print(\"  - data_processed/val_set.csv\")\n",
        "print(\"  - data_processed/test_set.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
