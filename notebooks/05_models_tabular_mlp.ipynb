{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b032f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\Users\\ersan\\OneDrive\\Masaüstü\\ders\\ceng481\\NBA-Game-Prediction-using-Artificial-Neural-Networks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# KENDİ PROJE KÖK YOLUN\n",
    "os.chdir(r\"C:\\Users\\ersan\\OneDrive\\Masaüstü\\ders\\ceng481\\NBA-Game-Prediction-using-Artificial-Neural-Networks\")\n",
    "print(\"CWD:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b7ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_processed/train_set.csv => OK\n",
      "data_processed/val_set.csv => OK\n",
      "data_processed/test_set.csv => OK\n",
      "src/models/mlp.py => OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for p in [\n",
    "    \"data_processed/train_set.csv\",\n",
    "    \"data_processed/val_set.csv\",\n",
    "    \"data_processed/test_set.csv\",\n",
    "    \"src/models/mlp.py\"\n",
    "]:\n",
    "    print(p, \"=>\", \"OK\" if os.path.exists(p) else \"MISSING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ac32fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SANITY CHECK ===\n",
      "[train] shape = (12746, 219)\n",
      "[train] total NaN = 26584\n",
      "[train] home_team_win dist = {1: 7341, 0: 5405}\n",
      "[val] shape = (2731, 219)\n",
      "[val] total NaN = 5648\n",
      "[val] home_team_win dist = {1: 1507, 0: 1224}\n",
      "[test] shape = (2732, 219)\n",
      "[test] total NaN = 5724\n",
      "[test] home_team_win dist = {1: 1567, 0: 1165}\n",
      "\n",
      "[LEAKAGE?] Flagged columns by heuristic:\n",
      " - away_roll_w10_avg_score_diff\n",
      " - away_roll_w5_avg_score_diff\n",
      " - diff_roll_w10_avg_score_diff\n",
      " - diff_roll_w5_avg_score_diff\n",
      " - home_roll_w10_avg_score_diff\n",
      " - home_roll_w5_avg_score_diff\n",
      " - home_team_WINpct\n",
      " - home_team_win\n",
      " - score_diff\n",
      "====================\n",
      "\n",
      "[WARN] Dropping 2 all-NaN columns from train features\n",
      "Epoch 1/200\n",
      "50/50 - 1s - 29ms/step - acc: 0.6054 - auc: 0.6294 - loss: 0.6619 - val_acc: 0.6390 - val_auc: 0.6786 - val_loss: 0.6411\n",
      "Epoch 2/200\n",
      "50/50 - 0s - 5ms/step - acc: 0.6358 - auc: 0.6737 - loss: 0.6352 - val_acc: 0.6452 - val_auc: 0.6858 - val_loss: 0.6387\n",
      "Epoch 3/200\n",
      "50/50 - 0s - 5ms/step - acc: 0.6434 - auc: 0.6836 - loss: 0.6299 - val_acc: 0.6456 - val_auc: 0.6909 - val_loss: 0.6344\n",
      "Epoch 4/200\n",
      "50/50 - 0s - 5ms/step - acc: 0.6467 - auc: 0.6927 - loss: 0.6240 - val_acc: 0.6485 - val_auc: 0.6935 - val_loss: 0.6328\n",
      "Epoch 5/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6533 - auc: 0.6982 - loss: 0.6200 - val_acc: 0.6466 - val_auc: 0.6891 - val_loss: 0.6345\n",
      "Epoch 6/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6557 - auc: 0.7034 - loss: 0.6161 - val_acc: 0.6456 - val_auc: 0.6871 - val_loss: 0.6359\n",
      "Epoch 7/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6561 - auc: 0.7044 - loss: 0.6147 - val_acc: 0.6496 - val_auc: 0.6909 - val_loss: 0.6334\n",
      "Epoch 8/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6593 - auc: 0.7113 - loss: 0.6110 - val_acc: 0.6507 - val_auc: 0.6929 - val_loss: 0.6316\n",
      "Epoch 9/200\n",
      "50/50 - 0s - 5ms/step - acc: 0.6618 - auc: 0.7147 - loss: 0.6085 - val_acc: 0.6518 - val_auc: 0.6912 - val_loss: 0.6328\n",
      "Epoch 10/200\n",
      "50/50 - 0s - 5ms/step - acc: 0.6619 - auc: 0.7203 - loss: 0.6050 - val_acc: 0.6481 - val_auc: 0.6914 - val_loss: 0.6330\n",
      "Epoch 11/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6704 - auc: 0.7211 - loss: 0.6035 - val_acc: 0.6456 - val_auc: 0.6885 - val_loss: 0.6334\n",
      "Epoch 12/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6722 - auc: 0.7223 - loss: 0.6022 - val_acc: 0.6474 - val_auc: 0.6860 - val_loss: 0.6367\n",
      "Epoch 13/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6705 - auc: 0.7270 - loss: 0.5980 - val_acc: 0.6426 - val_auc: 0.6865 - val_loss: 0.6367\n",
      "Epoch 14/200\n",
      "50/50 - 0s - 4ms/step - acc: 0.6723 - auc: 0.7302 - loss: 0.5952 - val_acc: 0.6423 - val_auc: 0.6845 - val_loss: 0.6387\n",
      "[MLP_C1] val_auc=0.6937\n",
      "Epoch 1/200\n",
      "50/50 - 1s - 20ms/step - acc: 0.6146 - auc: 0.6440 - loss: 0.6593 - val_acc: 0.6353 - val_auc: 0.6780 - val_loss: 0.6396\n",
      "Epoch 2/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.6505 - auc: 0.6972 - loss: 0.6202 - val_acc: 0.6390 - val_auc: 0.6847 - val_loss: 0.6369\n",
      "Epoch 3/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.6651 - auc: 0.7127 - loss: 0.6101 - val_acc: 0.6360 - val_auc: 0.6865 - val_loss: 0.6369\n",
      "Epoch 4/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.6741 - auc: 0.7236 - loss: 0.6025 - val_acc: 0.6415 - val_auc: 0.6862 - val_loss: 0.6378\n",
      "Epoch 5/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.6815 - auc: 0.7325 - loss: 0.5960 - val_acc: 0.6390 - val_auc: 0.6857 - val_loss: 0.6385\n",
      "Epoch 6/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.6860 - auc: 0.7407 - loss: 0.5900 - val_acc: 0.6368 - val_auc: 0.6844 - val_loss: 0.6396\n",
      "Epoch 7/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.6937 - auc: 0.7482 - loss: 0.5840 - val_acc: 0.6386 - val_auc: 0.6823 - val_loss: 0.6414\n",
      "Epoch 8/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.6981 - auc: 0.7562 - loss: 0.5777 - val_acc: 0.6368 - val_auc: 0.6806 - val_loss: 0.6434\n",
      "Epoch 9/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.7067 - auc: 0.7635 - loss: 0.5715 - val_acc: 0.6313 - val_auc: 0.6774 - val_loss: 0.6470\n",
      "Epoch 10/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.7111 - auc: 0.7708 - loss: 0.5651 - val_acc: 0.6305 - val_auc: 0.6742 - val_loss: 0.6506\n",
      "Epoch 11/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.7158 - auc: 0.7778 - loss: 0.5586 - val_acc: 0.6302 - val_auc: 0.6707 - val_loss: 0.6548\n",
      "Epoch 12/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.7212 - auc: 0.7853 - loss: 0.5517 - val_acc: 0.6254 - val_auc: 0.6692 - val_loss: 0.6580\n",
      "Epoch 13/200\n",
      "50/50 - 0s - 3ms/step - acc: 0.7280 - auc: 0.7929 - loss: 0.5447 - val_acc: 0.6276 - val_auc: 0.6671 - val_loss: 0.6613\n",
      "[MLP_C2] val_auc=0.6863\n",
      "Epoch 1/200\n",
      "50/50 - 3s - 52ms/step - acc: 0.5676 - auc: 0.5887 - loss: 0.8207 - val_acc: 0.6170 - val_auc: 0.6617 - val_loss: 0.6524\n",
      "Epoch 2/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.5944 - auc: 0.6147 - loss: 0.7333 - val_acc: 0.6335 - val_auc: 0.6689 - val_loss: 0.6467\n",
      "Epoch 3/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.5958 - auc: 0.6187 - loss: 0.7138 - val_acc: 0.6368 - val_auc: 0.6746 - val_loss: 0.6406\n",
      "Epoch 4/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6043 - auc: 0.6292 - loss: 0.6963 - val_acc: 0.6327 - val_auc: 0.6799 - val_loss: 0.6369\n",
      "Epoch 5/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6164 - auc: 0.6487 - loss: 0.6720 - val_acc: 0.6368 - val_auc: 0.6823 - val_loss: 0.6359\n",
      "Epoch 6/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6204 - auc: 0.6518 - loss: 0.6686 - val_acc: 0.6357 - val_auc: 0.6855 - val_loss: 0.6337\n",
      "Epoch 7/200\n",
      "50/50 - 1s - 10ms/step - acc: 0.6244 - auc: 0.6605 - loss: 0.6587 - val_acc: 0.6412 - val_auc: 0.6859 - val_loss: 0.6354\n",
      "Epoch 8/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6270 - auc: 0.6667 - loss: 0.6506 - val_acc: 0.6466 - val_auc: 0.6879 - val_loss: 0.6341\n",
      "Epoch 9/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6349 - auc: 0.6736 - loss: 0.6448 - val_acc: 0.6507 - val_auc: 0.6902 - val_loss: 0.6334\n",
      "Epoch 10/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6302 - auc: 0.6710 - loss: 0.6470 - val_acc: 0.6463 - val_auc: 0.6895 - val_loss: 0.6332\n",
      "Epoch 11/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6397 - auc: 0.6816 - loss: 0.6375 - val_acc: 0.6485 - val_auc: 0.6905 - val_loss: 0.6324\n",
      "Epoch 12/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6402 - auc: 0.6859 - loss: 0.6314 - val_acc: 0.6507 - val_auc: 0.6928 - val_loss: 0.6310\n",
      "Epoch 13/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6461 - auc: 0.6912 - loss: 0.6287 - val_acc: 0.6514 - val_auc: 0.6955 - val_loss: 0.6292\n",
      "Epoch 14/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6466 - auc: 0.6940 - loss: 0.6261 - val_acc: 0.6441 - val_auc: 0.6947 - val_loss: 0.6301\n",
      "Epoch 15/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6517 - auc: 0.7006 - loss: 0.6199 - val_acc: 0.6426 - val_auc: 0.6942 - val_loss: 0.6300\n",
      "Epoch 16/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6565 - auc: 0.7028 - loss: 0.6197 - val_acc: 0.6521 - val_auc: 0.6949 - val_loss: 0.6305\n",
      "Epoch 17/200\n",
      "50/50 - 1s - 10ms/step - acc: 0.6567 - auc: 0.7045 - loss: 0.6170 - val_acc: 0.6543 - val_auc: 0.6965 - val_loss: 0.6295\n",
      "Epoch 18/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6549 - auc: 0.7033 - loss: 0.6174 - val_acc: 0.6569 - val_auc: 0.6974 - val_loss: 0.6286\n",
      "Epoch 19/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6619 - auc: 0.7108 - loss: 0.6120 - val_acc: 0.6496 - val_auc: 0.6961 - val_loss: 0.6291\n",
      "Epoch 20/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6613 - auc: 0.7148 - loss: 0.6089 - val_acc: 0.6492 - val_auc: 0.6956 - val_loss: 0.6307\n",
      "Epoch 21/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6666 - auc: 0.7130 - loss: 0.6106 - val_acc: 0.6488 - val_auc: 0.6974 - val_loss: 0.6294\n",
      "Epoch 22/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6661 - auc: 0.7194 - loss: 0.6042 - val_acc: 0.6551 - val_auc: 0.6973 - val_loss: 0.6299\n",
      "Epoch 23/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6695 - auc: 0.7250 - loss: 0.6021 - val_acc: 0.6529 - val_auc: 0.6964 - val_loss: 0.6307\n",
      "Epoch 24/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6720 - auc: 0.7265 - loss: 0.6003 - val_acc: 0.6499 - val_auc: 0.6963 - val_loss: 0.6309\n",
      "Epoch 25/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6717 - auc: 0.7245 - loss: 0.6008 - val_acc: 0.6488 - val_auc: 0.6952 - val_loss: 0.6306\n",
      "Epoch 26/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6720 - auc: 0.7266 - loss: 0.5999 - val_acc: 0.6466 - val_auc: 0.6947 - val_loss: 0.6337\n",
      "Epoch 27/200\n",
      "50/50 - 0s - 8ms/step - acc: 0.6769 - auc: 0.7331 - loss: 0.5958 - val_acc: 0.6551 - val_auc: 0.6937 - val_loss: 0.6346\n",
      "Epoch 28/200\n",
      "50/50 - 0s - 9ms/step - acc: 0.6781 - auc: 0.7327 - loss: 0.5963 - val_acc: 0.6514 - val_auc: 0.6951 - val_loss: 0.6331\n",
      "[MLP_C3] val_auc=0.6974\n",
      "Epoch 1/200\n",
      "50/50 - 1s - 23ms/step - loss: 182.7894 - mae: 10.6978 - val_loss: 168.6338 - val_mae: 10.1078\n",
      "Epoch 2/200\n",
      "50/50 - 0s - 5ms/step - loss: 171.9514 - mae: 10.3255 - val_loss: 166.0192 - val_mae: 10.0019\n",
      "Epoch 3/200\n",
      "50/50 - 0s - 5ms/step - loss: 168.7814 - mae: 10.2129 - val_loss: 165.0732 - val_mae: 9.9762\n",
      "Epoch 4/200\n",
      "50/50 - 0s - 4ms/step - loss: 167.2240 - mae: 10.1563 - val_loss: 165.3917 - val_mae: 9.9865\n",
      "Epoch 5/200\n",
      "50/50 - 0s - 4ms/step - loss: 165.4213 - mae: 10.0993 - val_loss: 165.1518 - val_mae: 9.9826\n",
      "Epoch 6/200\n",
      "50/50 - 0s - 4ms/step - loss: 164.5342 - mae: 10.0761 - val_loss: 165.2146 - val_mae: 9.9831\n",
      "Epoch 7/200\n",
      "50/50 - 0s - 4ms/step - loss: 163.4821 - mae: 10.0429 - val_loss: 165.6358 - val_mae: 9.9929\n",
      "Epoch 8/200\n",
      "50/50 - 0s - 4ms/step - loss: 162.0730 - mae: 10.0010 - val_loss: 166.0939 - val_mae: 10.0085\n",
      "Epoch 9/200\n",
      "50/50 - 0s - 4ms/step - loss: 160.9880 - mae: 9.9709 - val_loss: 166.4786 - val_mae: 10.0295\n",
      "Epoch 10/200\n",
      "50/50 - 0s - 4ms/step - loss: 158.9699 - mae: 9.9089 - val_loss: 167.2814 - val_mae: 10.0362\n",
      "Epoch 11/200\n",
      "50/50 - 0s - 4ms/step - loss: 158.0692 - mae: 9.8957 - val_loss: 167.4638 - val_mae: 10.0446\n",
      "Epoch 12/200\n",
      "50/50 - 0s - 4ms/step - loss: 156.8129 - mae: 9.8592 - val_loss: 168.1680 - val_mae: 10.0596\n",
      "Epoch 13/200\n",
      "50/50 - 0s - 4ms/step - loss: 154.7665 - mae: 9.7919 - val_loss: 168.9019 - val_mae: 10.0797\n",
      "[MLP_R1] val_rmse=12.8481\n",
      "Epoch 1/200\n",
      "50/50 - 1s - 22ms/step - loss: 41.8785 - mae: 10.6393 - val_loss: 39.2165 - val_mae: 10.0646\n",
      "Epoch 2/200\n",
      "50/50 - 0s - 4ms/step - loss: 40.2920 - mae: 10.2957 - val_loss: 38.7620 - val_mae: 9.9689\n",
      "Epoch 3/200\n",
      "50/50 - 0s - 4ms/step - loss: 39.8136 - mae: 10.1920 - val_loss: 38.6142 - val_mae: 9.9435\n",
      "Epoch 4/200\n",
      "50/50 - 0s - 4ms/step - loss: 39.4614 - mae: 10.1183 - val_loss: 38.5496 - val_mae: 9.9289\n",
      "Epoch 5/200\n",
      "50/50 - 0s - 4ms/step - loss: 39.2212 - mae: 10.0647 - val_loss: 38.6430 - val_mae: 9.9462\n",
      "Epoch 6/200\n",
      "50/50 - 0s - 4ms/step - loss: 39.0484 - mae: 10.0229 - val_loss: 38.6455 - val_mae: 9.9500\n",
      "Epoch 7/200\n",
      "50/50 - 0s - 4ms/step - loss: 38.7518 - mae: 9.9631 - val_loss: 38.6515 - val_mae: 9.9465\n",
      "Epoch 8/200\n",
      "50/50 - 0s - 4ms/step - loss: 38.6576 - mae: 9.9391 - val_loss: 38.7090 - val_mae: 9.9614\n",
      "Epoch 9/200\n",
      "50/50 - 0s - 4ms/step - loss: 38.3258 - mae: 9.8652 - val_loss: 38.7871 - val_mae: 9.9754\n",
      "Epoch 10/200\n",
      "50/50 - 0s - 4ms/step - loss: 38.1050 - mae: 9.8138 - val_loss: 38.8219 - val_mae: 9.9798\n",
      "Epoch 11/200\n",
      "50/50 - 0s - 4ms/step - loss: 37.7768 - mae: 9.7393 - val_loss: 38.9445 - val_mae: 10.0099\n",
      "Epoch 12/200\n",
      "50/50 - 0s - 4ms/step - loss: 37.5477 - mae: 9.6973 - val_loss: 39.1170 - val_mae: 10.0430\n",
      "Epoch 13/200\n",
      "50/50 - 0s - 4ms/step - loss: 37.2819 - mae: 9.6397 - val_loss: 39.1007 - val_mae: 10.0377\n",
      "Epoch 14/200\n",
      "50/50 - 0s - 4ms/step - loss: 37.0692 - mae: 9.5974 - val_loss: 39.3298 - val_mae: 10.0818\n",
      "[MLP_R2] val_rmse=12.7927\n",
      "[OK] predictions -> data_processed/predictions_mlp.csv\n",
      "[OK] metrics -> reports/metrics/model_results.json\n",
      "\n",
      "DONE: MLP classifier + regressor\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 00:19:53.189408: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-22 00:19:56.035879: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:tensorflow:From c:\\Users\\ersan\\miniconda3\\envs\\ceng481\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "2025-12-22 00:19:58.783459: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-22 00:19:58.918743: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-12-22 00:20:03.982118: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-12-22 00:20:09.786901: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-12-22 00:20:21.941493: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-12-22 00:20:27.168261: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2025-12-22 00:20:32.543935: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    }
   ],
   "source": [
    "!python -m src.models.mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d2487c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred csv: True\n",
      "metrics json: True\n",
      "['split', 'y_true', 'y_prob', 'y_pred', 'score_diff_true', 'score_diff_pred']\n",
      "   split  y_true    y_prob  y_pred  score_diff_true  score_diff_pred\n",
      "0  train       1  0.341226       0             20.0        -2.891509\n",
      "1  train       0  0.204550       0            -17.0        -9.893769\n",
      "2  train       1  0.800694       1              9.0         7.102016\n",
      "3  train       1  0.372706       0             13.0        -4.294776\n",
      "4  train       1  0.767385       1              4.0         8.424859\n",
      "True True\n",
      "test AUC: 0.7096811654537936\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd, os\n",
    "\n",
    "print(\"pred csv:\", os.path.exists(\"data_processed/predictions_mlp.csv\"))\n",
    "print(\"metrics json:\", os.path.exists(\"reports/metrics/model_results.json\"))\n",
    "\n",
    "df = pd.read_csv(\"data_processed/predictions_mlp.csv\")\n",
    "print(df.columns.tolist())\n",
    "print(df.head())\n",
    "\n",
    "d = json.load(open(\"reports/metrics/model_results.json\",\"r\",encoding=\"utf-8\"))\n",
    "print(\"mlp_classifier\" in d, \"mlp_regressor\" in d)\n",
    "print(\"test AUC:\", d[\"mlp_classifier\"][\"test\"][\"roc_auc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6174442c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num figures: 15\n",
      "reports/figures/mlp\\classifier\\test_calibration.png\n",
      "reports/figures/mlp\\classifier\\test_confusion_matrix.png\n",
      "reports/figures/mlp\\classifier\\test_roc.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C1_accuracy.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C1_auc.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C1_loss.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C2_accuracy.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C2_auc.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C2_loss.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C3_accuracy.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C3_auc.png\n",
      "reports/figures/mlp\\classifier\\train_MLP_C3_loss.png\n",
      "reports/figures/mlp\\regressor\\test_scatter.png\n",
      "reports/figures/mlp\\regressor\\train_MLP_R1_loss.png\n",
      "reports/figures/mlp\\regressor\\train_MLP_R2_loss.png\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "paths = sorted(glob.glob(\"reports/figures/mlp/**/*.png\", recursive=True))\n",
    "print(\"num figures:\", len(paths))\n",
    "for p in paths[:30]:\n",
    "    print(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ceng481)",
   "language": "python",
   "name": "ceng481"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
